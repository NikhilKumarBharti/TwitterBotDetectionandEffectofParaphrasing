{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting charset-normalizer==3.1.0Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.41 requires requests_mock, which is not installed.\n",
      "conda-repo-cli 1.0.41 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires nbformat==5.4.0, but you have nbformat 5.7.0 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires requests==2.28.1, but you have requests 2.29.0 which is incompatible.\n",
      "aiohttp 3.8.1 requires charset-normalizer<3.0,>=2.0, but you have charset-normalizer 3.1.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached charset_normalizer-3.1.0-cp310-cp310-win_amd64.whl (97 kB)\n",
      "Installing collected packages: charset-normalizer\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.1.0\n",
      "    Uninstalling charset-normalizer-3.1.0:\n",
      "      Successfully uninstalled charset-normalizer-3.1.0\n",
      "Successfully installed charset-normalizer-3.1.0\n"
     ]
    }
   ],
   "source": [
    "pip install --force-reinstall charset-normalizer==3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your OpenAI API credentials\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and output CSV file paths\n",
    "input_file = \"fold_5.csv\"  # Replace with your input dataset file path\n",
    "output_file = \"paraphrased_fold_5.csv\"  # Replace with your desired output file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the input CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Define the number of columns to paraphrase (10 columns)\n",
    "num_rows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(559, 20)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column to paraphrase\n",
    "column_to_paraphrase = \"description\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of sentiment and voice options\n",
    "sentiments = [\"positive\", \"negative\"]\n",
    "voices = [\"active\", \"passive\"]\n",
    "\n",
    "# Shuffle the order of sentiments and voices\n",
    "random.shuffle(sentiments)\n",
    "random.shuffle(voices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paraphrase the selected column for the specified number of rows\n",
    "for i in range(num_rows):\n",
    "    original_text = df.loc[i, column_to_paraphrase]\n",
    "\n",
    "    # Choose a random sentiment and voice for each iteration\n",
    "    sentiment = sentiments[i % len(sentiments)]\n",
    "    voice = voices[i % len(voices)]\n",
    "\n",
    "    # Set the prompt with the instruction, sentiment, voice, and input text\n",
    "    prompt = f\"Rephrase, but don't change the essence of, the following text with {sentiment} sentiment and {voice} voice:\\n\\n{original_text}\\n\\nParaphrased Text:\"\n",
    "\n",
    "    # Generate the paraphrased text\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=50,\n",
    "        n=1,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "    # Extract the paraphrased text from the API response\n",
    "    paraphrased_text = response.choices[0].text.strip()\n",
    "\n",
    "    # Replace the original cell with the paraphrased cell in the DataFrame\n",
    "    df.loc[i, column_to_paraphrase] = paraphrased_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paraphrased dataset saved to paraphrased_fold_5.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Paraphrased dataset saved to\", output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
