{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ2VZKf69F1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "077aa414-30bf-4d6c-d460-178f238ffc31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-Vd2BuaneIk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import json\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "seed = 123\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "metadata": {
        "id": "hloHCtcDEpzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zg1scvvcSw1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f5e990a-7446-4652-aa81-dfeaa92f0b71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Check if a GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBL8oKyJKnU7"
      },
      "outputs": [],
      "source": [
        "# Define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size,batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        out = self.fc(h_n[-1])\n",
        "        return out\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return (torch.zeros(1, batch_size, self.hidden_size),\n",
        "                torch.zeros(1, batch_size, self.hidden_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yse9s8YGc6oO"
      },
      "outputs": [],
      "source": [
        "# Load the fold datasets\n",
        "fold1 = pd.read_csv('drive/MyDrive/Colab Notebooks/twitterbotdetection/cleanfold_1.csv')\n",
        "fold2 = pd.read_csv('drive/MyDrive/Colab Notebooks/twitterbotdetection/cleanfold_2.csv')\n",
        "fold3 = pd.read_csv('drive/MyDrive/Colab Notebooks/twitterbotdetection/cleanfold_3.csv')\n",
        "fold4 = pd.read_csv('drive/MyDrive/Colab Notebooks/twitterbotdetection/cleanfold_4.csv')\n",
        "fold5 = pd.read_csv('drive/MyDrive/Colab Notebooks/twitterbotdetection/cleanfold_5.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ElB9EhHeaKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d5b82a-fdca-4b5f-c028-46537b10d50d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(410, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "fold1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJF2poN1ecdJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "376d75d3-5882-48c3-9f59-dd47571ee33c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(410, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "fold2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxsGeaCBef1E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22782d00-e67f-4608-e478-a6ddd809596d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(410, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "fold3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuRstb5qeggN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82569011-fe8e-4f32-b2be-b41326340613"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(410, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "fold4.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hacqvrwehc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a07cdac-a587-4ddd-8259-890c41fc4f44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(410, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "fold5.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwaywo27dc96"
      },
      "outputs": [],
      "source": [
        "# Define the setups\n",
        "setups = [\n",
        "    {'train_folds': [fold2, fold3, fold4, fold5], 'test_fold': fold1},\n",
        "    {'train_folds': [fold3, fold4, fold5, fold1], 'test_fold': fold2},\n",
        "    {'train_folds': [fold4, fold5, fold1, fold2], 'test_fold': fold3},\n",
        "    {'train_folds': [fold5, fold1, fold2, fold3], 'test_fold': fold4},\n",
        "    {'train_folds': [fold1, fold2, fold3, fold4], 'test_fold': fold5},\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcCvSgewd92g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8da9e6e7-883a-425c-eac4-d8a467e23ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary saved to: vocabulary_setup1.txt\n",
            "Setup 1: Epoch: [1/10], Loss: 0.6594\n",
            "Setup 1: Epoch: [2/10], Loss: 0.5820\n",
            "Setup 1: Epoch: [3/10], Loss: 0.4055\n",
            "Setup 1: Epoch: [4/10], Loss: 0.3113\n",
            "Setup 1: Epoch: [5/10], Loss: 0.2132\n",
            "Setup 1: Epoch: [6/10], Loss: 0.2198\n",
            "Setup 1: Epoch: [7/10], Loss: 0.1071\n",
            "Setup 1: Epoch: [8/10], Loss: 0.0474\n",
            "Setup 1: Epoch: [9/10], Loss: 0.0624\n",
            "Setup 1: Epoch: [10/10], Loss: 0.0442\n",
            "Confidence scores saved to 'confidence_original1.csv'\n",
            "For Paraphrased Fold 1: Tested on: 410 instances, Test Accuracy: 0.8634, F1 Score for Label 0: 0.8733, F1 Score for Label 1: 0.8519\n",
            "Confidence_paraphrased scores saved to 'confidence_paraphrased1.csv'\n",
            "For Paraphrased Fold 1: Tested on: 410 instances, Test Accuracy: 0.8634, F1 Score for Label 0: 0.8733, F1 Score for Label 1: 0.8519\n",
            "Model saved\n",
            "\n",
            "Vocabulary saved to: vocabulary_setup2.txt\n",
            "Setup 2: Epoch: [1/10], Loss: 0.6556\n",
            "Setup 2: Epoch: [2/10], Loss: 0.5855\n",
            "Setup 2: Epoch: [3/10], Loss: 0.4055\n",
            "Setup 2: Epoch: [4/10], Loss: 0.3142\n",
            "Setup 2: Epoch: [5/10], Loss: 0.1660\n",
            "Setup 2: Epoch: [6/10], Loss: 0.1304\n",
            "Setup 2: Epoch: [7/10], Loss: 0.0985\n",
            "Setup 2: Epoch: [8/10], Loss: 0.1160\n",
            "Setup 2: Epoch: [9/10], Loss: 0.0365\n",
            "Setup 2: Epoch: [10/10], Loss: 0.0253\n",
            "Confidence scores saved to 'confidence_original2.csv'\n",
            "For Paraphrased Fold 2: Tested on: 410 instances, Test Accuracy: 0.8488, F1 Score for Label 0: 0.8565, F1 Score for Label 1: 0.8402\n",
            "Confidence_paraphrased scores saved to 'confidence_paraphrased2.csv'\n",
            "For Paraphrased Fold 2: Tested on: 410 instances, Test Accuracy: 0.8488, F1 Score for Label 0: 0.8565, F1 Score for Label 1: 0.8402\n",
            "Model saved\n",
            "\n",
            "Vocabulary saved to: vocabulary_setup3.txt\n",
            "Setup 3: Epoch: [1/10], Loss: 0.6604\n",
            "Setup 3: Epoch: [2/10], Loss: 0.5687\n",
            "Setup 3: Epoch: [3/10], Loss: 0.4322\n",
            "Setup 3: Epoch: [4/10], Loss: 0.3269\n",
            "Setup 3: Epoch: [5/10], Loss: 0.1926\n",
            "Setup 3: Epoch: [6/10], Loss: 0.1476\n",
            "Setup 3: Epoch: [7/10], Loss: 0.0957\n",
            "Setup 3: Epoch: [8/10], Loss: 0.0828\n",
            "Setup 3: Epoch: [9/10], Loss: 0.0726\n",
            "Setup 3: Epoch: [10/10], Loss: 0.0575\n",
            "Confidence scores saved to 'confidence_original3.csv'\n",
            "For Paraphrased Fold 3: Tested on: 410 instances, Test Accuracy: 0.8659, F1 Score for Label 0: 0.8681, F1 Score for Label 1: 0.8635\n",
            "Confidence_paraphrased scores saved to 'confidence_paraphrased3.csv'\n",
            "For Paraphrased Fold 3: Tested on: 410 instances, Test Accuracy: 0.8659, F1 Score for Label 0: 0.8681, F1 Score for Label 1: 0.8635\n",
            "Model saved\n",
            "\n",
            "Vocabulary saved to: vocabulary_setup4.txt\n",
            "Setup 4: Epoch: [1/10], Loss: 0.6560\n",
            "Setup 4: Epoch: [2/10], Loss: 0.6009\n",
            "Setup 4: Epoch: [3/10], Loss: 0.4289\n",
            "Setup 4: Epoch: [4/10], Loss: 0.3328\n",
            "Setup 4: Epoch: [5/10], Loss: 0.2216\n",
            "Setup 4: Epoch: [6/10], Loss: 0.1393\n",
            "Setup 4: Epoch: [7/10], Loss: 0.0742\n",
            "Setup 4: Epoch: [8/10], Loss: 0.1175\n",
            "Setup 4: Epoch: [9/10], Loss: 0.0460\n",
            "Setup 4: Epoch: [10/10], Loss: 0.0934\n",
            "Confidence scores saved to 'confidence_original4.csv'\n",
            "For Paraphrased Fold 4: Tested on: 410 instances, Test Accuracy: 0.8659, F1 Score for Label 0: 0.8662, F1 Score for Label 1: 0.8655\n",
            "Confidence_paraphrased scores saved to 'confidence_paraphrased4.csv'\n",
            "For Paraphrased Fold 4: Tested on: 410 instances, Test Accuracy: 0.8659, F1 Score for Label 0: 0.8662, F1 Score for Label 1: 0.8655\n",
            "Model saved\n",
            "\n",
            "Vocabulary saved to: vocabulary_setup5.txt\n",
            "Setup 5: Epoch: [1/10], Loss: 0.6665\n",
            "Setup 5: Epoch: [2/10], Loss: 0.5752\n",
            "Setup 5: Epoch: [3/10], Loss: 0.4522\n",
            "Setup 5: Epoch: [4/10], Loss: 0.3184\n",
            "Setup 5: Epoch: [5/10], Loss: 0.1651\n",
            "Setup 5: Epoch: [6/10], Loss: 0.1625\n",
            "Setup 5: Epoch: [7/10], Loss: 0.1292\n",
            "Setup 5: Epoch: [8/10], Loss: 0.0763\n",
            "Setup 5: Epoch: [9/10], Loss: 0.0419\n",
            "Setup 5: Epoch: [10/10], Loss: 0.0355\n",
            "Confidence scores saved to 'confidence_original5.csv'\n",
            "For Paraphrased Fold 5: Tested on: 410 instances, Test Accuracy: 0.8829, F1 Score for Label 0: 0.8846, F1 Score for Label 1: 0.8812\n",
            "Confidence_paraphrased scores saved to 'confidence_paraphrased5.csv'\n",
            "For Paraphrased Fold 5: Tested on: 410 instances, Test Accuracy: 0.8829, F1 Score for Label 0: 0.8846, F1 Score for Label 1: 0.8812\n",
            "Model saved\n",
            "\n"
          ]
        }
      ],
      "source": [
        "setup_no=1\n",
        "# Create empty lists to store precision and recall values\n",
        "precision_0_list = []\n",
        "recall_0_list = []\n",
        "precision_1_list = []\n",
        "recall_1_list = []\n",
        "\n",
        "precision_0_list_para = []\n",
        "recall_0_list_para = []\n",
        "precision_1_list_para = []\n",
        "recall_1_list_para = []\n",
        "\n",
        "f1_orig_0_list = []\n",
        "f1_orig_1_list = []\n",
        "f1_para_0_list = []\n",
        "f1_para_1_list = []\n",
        "\n",
        "# Train and evaluate for each setup\n",
        "for i, setup in enumerate(setups):\n",
        "    len_instances=0\n",
        "    train_folds = setup['train_folds']\n",
        "    test_fold = setup['test_fold']\n",
        "\n",
        "    # Concatenate all the train folds\n",
        "    train_data = pd.concat(train_folds)\n",
        "\n",
        "    train_data_cols = train_data[['location','description','verified']]\n",
        "    test_data_cols = test_fold[['location','description','verified']]\n",
        "\n",
        "    tested_ids = []\n",
        "\n",
        "\n",
        "    # Perform data vectorization\n",
        "    vectorizer = CountVectorizer(stop_words='english')\n",
        "    X_train_vectorized = vectorizer.fit_transform(train_data_cols.apply(lambda x: ' '.join(map(str,x)), axis=1))\n",
        "    X_test_vectorized = vectorizer.transform(test_data_cols.apply(lambda x: ' '.join(map(str,x)), axis=1))\n",
        "\n",
        "    # Get the vocabulary (i.e., mapping from words to indices)\n",
        "    vocabulary = vectorizer.vocabulary_\n",
        "\n",
        "    # Convert the vocabulary to a JSON string\n",
        "    vocabulary_json = json.dumps(vocabulary)\n",
        "\n",
        "    # Specify the file path to save the vocabulary\n",
        "    file_path = f\"vocabulary_setup{setup_no}.txt\"\n",
        "\n",
        "    # Save the vocabulary to the text file\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(vocabulary_json)\n",
        "\n",
        "    print(f\"Vocabulary saved to: {file_path}\")\n",
        "\n",
        "    #X_test_vectorized = vectorizer.transform(test_data['text_column'])\n",
        "    y_train = train_data['bot']\n",
        "    y_test = test_fold['bot']\n",
        "\n",
        "    # Reshape the output labels to a 1D array\n",
        "    y_reshaped = np.array(y_train).reshape(-1)\n",
        "    y_test_reshaped = np.array(y_test).reshape(-1)\n",
        "\n",
        "    # Encode the output labels using LabelEncoder\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(y_reshaped)\n",
        "    y_test_encoded = label_encoder.transform(y_test_reshaped)\n",
        "\n",
        "    # Convert the data to tensors\n",
        "    X_train_tensor = torch.tensor(X_train_vectorized.toarray(), dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_encoded, dtype=torch.float32)\n",
        "    X_test_tensor = torch.tensor(X_test_vectorized.toarray(), dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.float32)\n",
        "\n",
        "\n",
        "    # Set hyperparameters\n",
        "    input_size = X_train_tensor.shape[1]\n",
        "    hidden_size = 64\n",
        "    output_size = 1\n",
        "    num_epochs = 10\n",
        "    batch_size = 32\n",
        "    learning_rate = 0.001\n",
        "\n",
        "    # Create the LSTM model\n",
        "    model = LSTMModel(input_size, hidden_size, output_size)\n",
        "    model.to(device)\n",
        "\n",
        "    # Define the loss function and optimizer\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Create a DataLoader for training\n",
        "    train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_samples = 0\n",
        "        correct_predictions = 0\n",
        "        test_f1_score = 0.0\n",
        "        test_accuracy = 0.0\n",
        "\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            batch_X = batch_X.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "            outputs = model(batch_X.unsqueeze(1))\n",
        "            batch_size = batch_X.size(0)\n",
        "\n",
        "            # Reshape the output tensor to match the target tensor shape\n",
        "            outputs = outputs.view(batch_size)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Setup {setup_no}: Epoch: [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    len_instances = sum(len(train_fold) for train_fold in train_folds)\n",
        "\n",
        "\n",
        "\n",
        "    # Evaluate the model on the test fold\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(X_test_tensor.to(device).unsqueeze(1))\n",
        "        test_predictions = torch.round(torch.sigmoid(test_outputs)).cpu().numpy()\n",
        "        test_accuracy = accuracy_score(y_test_encoded, test_predictions)\n",
        "        test_f1_score_orig_label0 = f1_score(y_test_encoded==0, test_predictions==0)\n",
        "        test_f1_score_orig_label1 = f1_score(y_test_encoded==1, test_predictions==1)\n",
        "\n",
        "        test_probabilities = torch.sigmoid(test_outputs).cpu().numpy()\n",
        "\n",
        "        # Calculate precision and recall for class 0\n",
        "        precision_0 = precision_score(y_test_encoded, test_predictions, pos_label=0)\n",
        "        recall_0 = recall_score(y_test_encoded, test_predictions, pos_label=0)\n",
        "\n",
        "        # Calculate precision and recall for class 1\n",
        "        precision_1 = precision_score(y_test_encoded, test_predictions, pos_label=1)\n",
        "        recall_1 = recall_score(y_test_encoded, test_predictions, pos_label=1)\n",
        "\n",
        "        # Calculate the confidence score for label 1\n",
        "        confidence_scores_label1 = test_probabilities[:, 0]\n",
        "\n",
        "        # Ensure test_predictions and y_test_encoded have the same length\n",
        "        num_instances = len(test_fold)\n",
        "        test_predictions = test_predictions[:num_instances]\n",
        "\n",
        "        # Convert the predicted labels to strings\n",
        "        predicted_labels = test_predictions.astype(str)\n",
        "\n",
        "        # Create a DataFrame with the predicted labels\n",
        "        predictions_df = pd.DataFrame({\n",
        "            'id_str': test_fold['id_str'],  # Include the 'id_str' column\n",
        "            'Predicted Label': [', '.join(labels) for labels in predicted_labels]\n",
        "        })\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        predictions_df.to_csv(f\"predictions_setup{setup_no}.csv\", index=False)\n",
        "\n",
        "        # Create a DataFrame with id_str and confidence scores\n",
        "        confidence_df = pd.DataFrame({\n",
        "            'id_str': test_fold['id_str'],\n",
        "            'Confidence Label 1 Original': confidence_scores_label1\n",
        "        })\n",
        "\n",
        "        # Specify the output CSV file path\n",
        "        csv_file = f\"confidence_original{setup_no}.csv\"\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        confidence_df.to_csv(csv_file, index=False)\n",
        "\n",
        "        print(f\"Confidence scores saved to '{csv_file}'\")\n",
        "\n",
        "        tested_ids.extend(test_fold['id_str'])\n",
        "\n",
        "        # Append precision and recall values to their respective lists\n",
        "        precision_0_list.append(precision_0)\n",
        "        recall_0_list.append(recall_0)\n",
        "        precision_1_list.append(precision_1)\n",
        "        recall_1_list.append(recall_1)\n",
        "\n",
        "        f1_orig_0_list.append(test_f1_score_orig_label0)\n",
        "        f1_orig_1_list.append(test_f1_score_orig_label1)\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"For Paraphrased Fold {setup_no}: Tested on: {len(test_fold)} instances, Test Accuracy: {test_accuracy:.4f}, F1 Score for Label 0: {test_f1_score_orig_label0:.4f}, F1 Score for Label 1: {test_f1_score_orig_label1:.4f}\")\n",
        "\n",
        "    #Forparaphrasedfifthfold\n",
        "    paraphrased_fold=pd.read_csv(f'drive/MyDrive/Colab Notebooks/twitterbotdetection/cleanfold_{setup_no}.csv')\n",
        "    paraphrased_fold_filtered = paraphrased_fold[paraphrased_fold['id_str'].isin(tested_ids)]\n",
        "    X_test_vectorized = vectorizer.transform(paraphrased_fold_filtered[['location','description','verified']].apply(lambda x: ' '.join(map(str,x)), axis=1))\n",
        "\n",
        "    y_test = paraphrased_fold_filtered['bot']\n",
        "\n",
        "    y_test_reshaped = np.array(y_test).reshape(-1)\n",
        "\n",
        "    y_test_encoded = label_encoder.transform(y_test_reshaped)\n",
        "\n",
        "    X_test_tensor = torch.tensor(X_test_vectorized.toarray(), dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.float32)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(X_test_tensor.to(device).unsqueeze(1))\n",
        "        test_predictions = torch.round(torch.sigmoid(test_outputs)).cpu().numpy()\n",
        "        test_accuracy = accuracy_score(y_test_encoded, test_predictions)\n",
        "        test_f1_score_para_label0 = f1_score(y_test_encoded==0, test_predictions==0)\n",
        "        test_f1_score_para_label1 = f1_score(y_test_encoded==1, test_predictions==1)\n",
        "\n",
        "\n",
        "        test_probabilities = torch.sigmoid(test_outputs).cpu().numpy()\n",
        "\n",
        "        # Calculate precision and recall for class 0\n",
        "        precision_0_para = precision_score(y_test_encoded, test_predictions, pos_label=0)\n",
        "        recall_0_para = recall_score(y_test_encoded, test_predictions, pos_label=0)\n",
        "\n",
        "        # Calculate precision and recall for class 1\n",
        "        precision_1_para = precision_score(y_test_encoded, test_predictions, pos_label=1)\n",
        "        recall_1_para = recall_score(y_test_encoded, test_predictions, pos_label=1)\n",
        "\n",
        "        # Calculate the confidence score for label 1\n",
        "        confidence_paraphrased_label1 = test_probabilities[:, 0]\n",
        "\n",
        "        # Ensure test_predictions and y_test_encoded have the same length\n",
        "        num_instances = len(paraphrased_fold_filtered)\n",
        "        test_predictions = test_predictions[:num_instances]\n",
        "\n",
        "        # Convert the predicted labels to strings\n",
        "        predicted_labels = test_predictions.astype(str)\n",
        "\n",
        "        # Create a DataFrame with the predicted labels\n",
        "        predictions_df = pd.DataFrame({\n",
        "            'id_str': paraphrased_fold_filtered['id_str'],  # Include the 'id_str' column\n",
        "            'Predicted Label Original': [', '.join(labels) for labels in predicted_labels]\n",
        "        })\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        predictions_df.to_csv(f\"f{setup_no}_predictions.csv\", index=False)\n",
        "\n",
        "        # Create a DataFrame with id_str and confidence scores\n",
        "        confidence_df = pd.DataFrame({\n",
        "            'id_str': paraphrased_fold_filtered['id_str'],\n",
        "            'Confidence Label 1 Paraphrased': confidence_paraphrased_label1\n",
        "        })\n",
        "\n",
        "        # Specify the output CSV file path\n",
        "        csv_file = f\"confidence_paraphrased{setup_no}.csv\"\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        confidence_df.to_csv(csv_file, index=False)\n",
        "\n",
        "        print(f\"Confidence_paraphrased scores saved to '{csv_file}'\")\n",
        "\n",
        "        # Append precision and recall values to their respective lists\n",
        "        precision_0_list_para.append(precision_0_para)\n",
        "        recall_0_list_para.append(recall_0_para)\n",
        "        precision_1_list_para.append(precision_1_para)\n",
        "        recall_1_list_para.append(recall_1_para)\n",
        "\n",
        "        f1_para_0_list.append(test_f1_score_para_label0)\n",
        "        f1_para_1_list.append(test_f1_score_para_label1)\n",
        "\n",
        "    print(f\"For Paraphrased Fold {setup_no}: Tested on: {len(paraphrased_fold_filtered)} instances, Test Accuracy: {test_accuracy:.4f}, F1 Score for Label 0: {test_f1_score_para_label0:.4f}, F1 Score for Label 1: {test_f1_score_para_label1:.4f}\")\n",
        "\n",
        "    # Save the model after each setup\n",
        "    torch.save(model.state_dict(), f\"model_setup{setup_no}.pt\")\n",
        "    print('Model saved')\n",
        "    setup_no=setup_no+1\n",
        "\n",
        "    print()  # Add an empty line between setups"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the 'id_str' column values from each DataFrame\n",
        "id_str1 = test_fold['id_str']\n",
        "id_str2 = paraphrased_fold['id_str']\n",
        "\n",
        "# Compare the 'id_str' values and find the matching instances\n",
        "matching_instances = id_str1.isin(id_str2)\n",
        "\n",
        "# Count the number of matching instances\n",
        "num_matching_instances = matching_instances.sum()\n",
        "\n",
        "# Display the result\n",
        "print(f\"Number of matching instances: {num_matching_instances}\")"
      ],
      "metadata": {
        "id": "k0-AREVmNbid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41595cab-6e0f-4375-e5b0-79618bba6814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of matching instances: 410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the performance metrics\n",
        "print(precision_0_list)\n",
        "print(recall_0_list)\n",
        "print(precision_1_list)\n",
        "print(recall_1_list)\n",
        "print()\n",
        "print(precision_0_list_para)\n",
        "print(recall_0_list_para)\n",
        "print(precision_1_list_para)\n",
        "print(recall_1_list_para)\n",
        "print()\n",
        "print(f1_orig_0_list)\n",
        "print(f1_orig_1_list)\n",
        "print()\n",
        "print(f1_para_0_list)\n",
        "print(f1_para_1_list)"
      ],
      "metadata": {
        "id": "sFurLHRcyaCI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c782dc-7ed5-450a-d945-5706a5940bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8654708520179372, 0.8564814814814815, 0.8829268292682927, 0.8436018957345972, 0.8975609756097561]\n",
            "[0.8812785388127854, 0.8564814814814815, 0.8537735849056604, 0.89, 0.8720379146919431]\n",
            "[0.8609625668449198, 0.8402061855670103, 0.848780487804878, 0.8894472361809045, 0.8682926829268293]\n",
            "[0.8429319371727748, 0.8402061855670103, 0.8787878787878788, 0.8428571428571429, 0.8944723618090452]\n",
            "\n",
            "[0.8654708520179372, 0.8564814814814815, 0.8829268292682927, 0.8436018957345972, 0.8975609756097561]\n",
            "[0.8812785388127854, 0.8564814814814815, 0.8537735849056604, 0.89, 0.8720379146919431]\n",
            "[0.8609625668449198, 0.8402061855670103, 0.848780487804878, 0.8894472361809045, 0.8682926829268293]\n",
            "[0.8429319371727748, 0.8402061855670103, 0.8787878787878788, 0.8428571428571429, 0.8944723618090452]\n",
            "\n",
            "[0.8733031674208145, 0.8564814814814815, 0.8681055155875299, 0.8661800486618004, 0.8846153846153846]\n",
            "[0.8518518518518517, 0.8402061855670103, 0.8635235732009925, 0.8655256723716381, 0.8811881188118812]\n",
            "\n",
            "[0.8733031674208145, 0.8564814814814815, 0.8681055155875299, 0.8661800486618004, 0.8846153846153846]\n",
            "[0.8518518518518517, 0.8402061855670103, 0.8635235732009925, 0.8655256723716381, 0.8811881188118812]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}