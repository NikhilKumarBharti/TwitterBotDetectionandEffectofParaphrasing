{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ2VZKf69F1G",
        "outputId": "64bc1583-f3cd-4470-f7c7-c20b2f4957ce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "X-Vd2BuaneIk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size,batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        out = self.fc(h_n[-1])\n",
        "        return out\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return (torch.zeros(1, batch_size, self.hidden_size),\n",
        "                torch.zeros(1, batch_size, self.hidden_size))"
      ],
      "metadata": {
        "id": "HBL8oKyJKnU7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your data into a pandas DataFrame\n",
        "base_csv = 'drive/MyDrive/Colab Notebooks/twitterbotdetection/training_data_2_csv_UTF.csv'\n",
        "df = pd.read_csv(base_csv)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "tQ4-ZdqnocIL",
        "outputId": "504fc6c9-3e6f-4034-f77a-51201ed4197a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             id                id_str       screen_name  \\\n",
              "0  8.160000e+17  \"815745789754417152\"  \"HoustonPokeMap\"   \n",
              "1  4.843621e+09            4843621225         kernyeahx   \n",
              "2  4.303727e+09            4303727112   mattlieberisbot   \n",
              "3  3.063139e+09            3063139353         sc_papers   \n",
              "4  2.955142e+09            2955142070      lucarivera16   \n",
              "\n",
              "                    location  \\\n",
              "0              \"Houston, TX\"   \n",
              "1  Templeville town, MD, USA   \n",
              "2                        NaN   \n",
              "3                        NaN   \n",
              "4      Dublin, United States   \n",
              "\n",
              "                                         description  \\\n",
              "0  \"Rare and strong PokŽmon in Houston, TX. See m...   \n",
              "1  From late 2014 Socium Marketplace will make sh...   \n",
              "2  Inspired by the smart, funny folks at @replyal...   \n",
              "3                                                NaN   \n",
              "4             Inspiring cooks everywhere since 1956.   \n",
              "\n",
              "                         url  followers_count  friends_count  listed_count  \\\n",
              "0  \"https://t.co/dnWuDbFRkt\"             1291              0            10   \n",
              "1                        NaN                1            349             0   \n",
              "2    https://t.co/P1e1o0m4KC             1086              0            14   \n",
              "3                        NaN               33              0             8   \n",
              "4                        NaN               11            745             0   \n",
              "\n",
              "                         created_at  favourites_count  verified  \\\n",
              "0  \"Mon Jan 02 02:25:26 +0000 2017\"                 0     False   \n",
              "1                     2/1/2016 7:37                38     False   \n",
              "2    Fri Nov 20 18:53:22 +0000 2015                 0     False   \n",
              "3                   2/25/2015 20:11                 0     False   \n",
              "4                    1/1/2015 17:44               146     False   \n",
              "\n",
              "   statuses_count  lang                                             status  \\\n",
              "0           78554  \"en\"  {\\r      \"created_at\": \"Sun Mar 12 15:44:04 +0...   \n",
              "1              31    en                                                NaN   \n",
              "2             713    en  {'retweeted': False, 'is_quote_status': False,...   \n",
              "3             676    en  Construction of human anti-tetanus single-chai...   \n",
              "4             185    en                                                NaN   \n",
              "\n",
              "   default_profile  default_profile_image has_extended_profile  \\\n",
              "0             True                  False                False   \n",
              "1             True                  False                False   \n",
              "2             True                  False                False   \n",
              "3             True                   True                False   \n",
              "4            False                  False                False   \n",
              "\n",
              "                   name  bot  \n",
              "0  \"Houston PokŽ Alert\"    1  \n",
              "1           Keri Nelson    1  \n",
              "2    Matt Lieber Is Bot    1  \n",
              "3    single cell papers    1  \n",
              "4          lucarivera16    1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-893e46d0-6db3-4ec5-afdc-bc0ec6be30af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>id_str</th>\n",
              "      <th>screen_name</th>\n",
              "      <th>location</th>\n",
              "      <th>description</th>\n",
              "      <th>url</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>friends_count</th>\n",
              "      <th>listed_count</th>\n",
              "      <th>created_at</th>\n",
              "      <th>favourites_count</th>\n",
              "      <th>verified</th>\n",
              "      <th>statuses_count</th>\n",
              "      <th>lang</th>\n",
              "      <th>status</th>\n",
              "      <th>default_profile</th>\n",
              "      <th>default_profile_image</th>\n",
              "      <th>has_extended_profile</th>\n",
              "      <th>name</th>\n",
              "      <th>bot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.160000e+17</td>\n",
              "      <td>\"815745789754417152\"</td>\n",
              "      <td>\"HoustonPokeMap\"</td>\n",
              "      <td>\"Houston, TX\"</td>\n",
              "      <td>\"Rare and strong PokŽmon in Houston, TX. See m...</td>\n",
              "      <td>\"https://t.co/dnWuDbFRkt\"</td>\n",
              "      <td>1291</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>\"Mon Jan 02 02:25:26 +0000 2017\"</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>78554</td>\n",
              "      <td>\"en\"</td>\n",
              "      <td>{\\r      \"created_at\": \"Sun Mar 12 15:44:04 +0...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>\"Houston PokŽ Alert\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.843621e+09</td>\n",
              "      <td>4843621225</td>\n",
              "      <td>kernyeahx</td>\n",
              "      <td>Templeville town, MD, USA</td>\n",
              "      <td>From late 2014 Socium Marketplace will make sh...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>349</td>\n",
              "      <td>0</td>\n",
              "      <td>2/1/2016 7:37</td>\n",
              "      <td>38</td>\n",
              "      <td>False</td>\n",
              "      <td>31</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Keri Nelson</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.303727e+09</td>\n",
              "      <td>4303727112</td>\n",
              "      <td>mattlieberisbot</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Inspired by the smart, funny folks at @replyal...</td>\n",
              "      <td>https://t.co/P1e1o0m4KC</td>\n",
              "      <td>1086</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>Fri Nov 20 18:53:22 +0000 2015</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>713</td>\n",
              "      <td>en</td>\n",
              "      <td>{'retweeted': False, 'is_quote_status': False,...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Matt Lieber Is Bot</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.063139e+09</td>\n",
              "      <td>3063139353</td>\n",
              "      <td>sc_papers</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2/25/2015 20:11</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>676</td>\n",
              "      <td>en</td>\n",
              "      <td>Construction of human anti-tetanus single-chai...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>single cell papers</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.955142e+09</td>\n",
              "      <td>2955142070</td>\n",
              "      <td>lucarivera16</td>\n",
              "      <td>Dublin, United States</td>\n",
              "      <td>Inspiring cooks everywhere since 1956.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11</td>\n",
              "      <td>745</td>\n",
              "      <td>0</td>\n",
              "      <td>1/1/2015 17:44</td>\n",
              "      <td>146</td>\n",
              "      <td>False</td>\n",
              "      <td>185</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>lucarivera16</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-893e46d0-6db3-4ec5-afdc-bc0ec6be30af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-893e46d0-6db3-4ec5-afdc-bc0ec6be30af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-893e46d0-6db3-4ec5-afdc-bc0ec6be30af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_imputed=df.fillna(df.mode().iloc[0])"
      ],
      "metadata": {
        "id": "YIUkjHutAWQ_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of desired folds\n",
        "num_folds = 5\n",
        "\n",
        "# Initialize the KFold object\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "HGbq3hd_aVBh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty lists to store the indices of each fold\n",
        "fold_indices = []"
      ],
      "metadata": {
        "id": "hoVIZy5faWV8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into folds\n",
        "for train_index, _ in kfold.split(df_imputed):\n",
        "    fold_indices.append(train_index)"
      ],
      "metadata": {
        "id": "MWFEm4xTaZxU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the first 4 folds\n",
        "for fold in range(num_folds - 1):  # Iterate over the first 4 folds\n",
        "    train_indices = fold_indices[fold]\n",
        "    test_indices = fold_indices[num_folds - 1]  # Index of the corresponding test fold\n",
        "\n",
        "    # Get the data for the current fold\n",
        "    train_data = df_imputed.iloc[train_indices]\n",
        "    test_data = df_imputed.iloc[test_indices]\n",
        "    test_data.to_csv('fifthfold.csv', index=False)\n",
        "\n",
        "    # Perform data vectorization\n",
        "    vectorizer = CountVectorizer()\n",
        "    X_train_vectorized = vectorizer.fit_transform(train_data.drop('bot',axis=1).apply(lambda x: ' '.join(map(str,x)), axis=1))\n",
        "    #X_test_vectorized = vectorizer.transform(test_data['text_column'])\n",
        "    y_train = train_data['bot']\n",
        "\n",
        "\n",
        "    # Reshape the output labels to a 2D array\n",
        "    y_reshaped = np.array(y_train).reshape(-1, 1)\n",
        "    # Encode the output labels\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    y_encoded = mlb.fit_transform(y_reshaped)\n",
        "\n",
        "    # Convert the data to tensors\n",
        "    X_train_tensor = torch.tensor(X_train_vectorized.toarray(), dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_encoded, dtype=torch.float32)\n",
        "\n",
        "    # Set hyperparameters\n",
        "    input_size = X_train_tensor.shape[1]\n",
        "    hidden_size = 64\n",
        "    output_size = y_train_tensor.shape[1]\n",
        "    num_epochs = 10\n",
        "    batch_size = 32\n",
        "    learning_rate = 0.001\n",
        "\n",
        "    # Create the LSTM model\n",
        "    model = LSTMModel(input_size, hidden_size, output_size)\n",
        "\n",
        "    # Define the loss function and optimizer\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Create a DataLoader for training\n",
        "    train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_samples = 0\n",
        "        correct_predictions = 0\n",
        "        test_f1_score = 0.0\n",
        "        test_accuracy = 0.0\n",
        "\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X.unsqueeze(1))\n",
        "            loss = criterion(outputs.squeeze(), batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Fold {fold} : Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Train Indices: {train_indices}\")\n",
        "\n",
        "    # Save the trained model for each fold\n",
        "    LSTM5folds = f\"model_fold_{fold}.pth\"\n",
        "    torch.save(model.state_dict(), LSTM5folds)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IK_EAax6cvV-",
        "outputId": "f5408a19-55e3-4ed0-f892-4a7c3ea5786e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 : Epoch [1/10], Loss: 0.6157, Train Indices: [   0    1    2 ... 2793 2794 2795]\n",
            "Fold 0 : Epoch [2/10], Loss: 0.3246, Train Indices: [   0    1    2 ... 2793 2794 2795]\n",
            "Fold 0 : Epoch [3/10], Loss: 0.2372, Train Indices: [   0    1    2 ... 2793 2794 2795]\n",
            "Fold 0 : Epoch [4/10], Loss: 0.0504, Train Indices: [   0    1    2 ... 2793 2794 2795]\n",
            "Fold 0 : Epoch [5/10], Loss: 0.0538, Train Indices: [   0    1    2 ... 2793 2794 2795]\n",
            "Fold 0 : Epoch [6/10], Loss: 0.0159, Train Indices: [   0    1    2 ... 2793 2794 2795]\n",
            "Fold 0 : Epoch [7/10], Loss: 0.0143, Train Indices: [   0    1    2 ... 2793 2794 2795]\n",
            "Fold 0 : Epoch [8/10], Loss: 0.0066, Train Indices: [   0    1    2 ... 2793 2794 2795]\n",
            "Fold 0 : Epoch [9/10], Loss: 0.0050, Train Indices: [   0    1    2 ... 2793 2794 2795]\n",
            "Fold 0 : Epoch [10/10], Loss: 0.0226, Train Indices: [   0    1    2 ... 2793 2794 2795]\n",
            "Fold 1 : Epoch [1/10], Loss: 0.5472, Train Indices: [   0    1    2 ... 2794 2795 2796]\n",
            "Fold 1 : Epoch [2/10], Loss: 0.3449, Train Indices: [   0    1    2 ... 2794 2795 2796]\n",
            "Fold 1 : Epoch [3/10], Loss: 0.1594, Train Indices: [   0    1    2 ... 2794 2795 2796]\n",
            "Fold 1 : Epoch [4/10], Loss: 0.0487, Train Indices: [   0    1    2 ... 2794 2795 2796]\n",
            "Fold 1 : Epoch [5/10], Loss: 0.0445, Train Indices: [   0    1    2 ... 2794 2795 2796]\n",
            "Fold 1 : Epoch [6/10], Loss: 0.0364, Train Indices: [   0    1    2 ... 2794 2795 2796]\n",
            "Fold 1 : Epoch [7/10], Loss: 0.0132, Train Indices: [   0    1    2 ... 2794 2795 2796]\n",
            "Fold 1 : Epoch [8/10], Loss: 0.0208, Train Indices: [   0    1    2 ... 2794 2795 2796]\n",
            "Fold 1 : Epoch [9/10], Loss: 0.0073, Train Indices: [   0    1    2 ... 2794 2795 2796]\n",
            "Fold 1 : Epoch [10/10], Loss: 0.0028, Train Indices: [   0    1    2 ... 2794 2795 2796]\n",
            "Fold 2 : Epoch [1/10], Loss: 0.5912, Train Indices: [   0    1    3 ... 2792 2793 2796]\n",
            "Fold 2 : Epoch [2/10], Loss: 0.3677, Train Indices: [   0    1    3 ... 2792 2793 2796]\n",
            "Fold 2 : Epoch [3/10], Loss: 0.2190, Train Indices: [   0    1    3 ... 2792 2793 2796]\n",
            "Fold 2 : Epoch [4/10], Loss: 0.0560, Train Indices: [   0    1    3 ... 2792 2793 2796]\n",
            "Fold 2 : Epoch [5/10], Loss: 0.0250, Train Indices: [   0    1    3 ... 2792 2793 2796]\n",
            "Fold 2 : Epoch [6/10], Loss: 0.0195, Train Indices: [   0    1    3 ... 2792 2793 2796]\n",
            "Fold 2 : Epoch [7/10], Loss: 0.0139, Train Indices: [   0    1    3 ... 2792 2793 2796]\n",
            "Fold 2 : Epoch [8/10], Loss: 0.0140, Train Indices: [   0    1    3 ... 2792 2793 2796]\n",
            "Fold 2 : Epoch [9/10], Loss: 0.0067, Train Indices: [   0    1    3 ... 2792 2793 2796]\n",
            "Fold 2 : Epoch [10/10], Loss: 0.0048, Train Indices: [   0    1    3 ... 2792 2793 2796]\n",
            "Fold 3 : Epoch [1/10], Loss: 0.5753, Train Indices: [   1    2    4 ... 2794 2795 2796]\n",
            "Fold 3 : Epoch [2/10], Loss: 0.2724, Train Indices: [   1    2    4 ... 2794 2795 2796]\n",
            "Fold 3 : Epoch [3/10], Loss: 0.1603, Train Indices: [   1    2    4 ... 2794 2795 2796]\n",
            "Fold 3 : Epoch [4/10], Loss: 0.0527, Train Indices: [   1    2    4 ... 2794 2795 2796]\n",
            "Fold 3 : Epoch [5/10], Loss: 0.0523, Train Indices: [   1    2    4 ... 2794 2795 2796]\n",
            "Fold 3 : Epoch [6/10], Loss: 0.0142, Train Indices: [   1    2    4 ... 2794 2795 2796]\n",
            "Fold 3 : Epoch [7/10], Loss: 0.0185, Train Indices: [   1    2    4 ... 2794 2795 2796]\n",
            "Fold 3 : Epoch [8/10], Loss: 0.0151, Train Indices: [   1    2    4 ... 2794 2795 2796]\n",
            "Fold 3 : Epoch [9/10], Loss: 0.0073, Train Indices: [   1    2    4 ... 2794 2795 2796]\n",
            "Fold 3 : Epoch [10/10], Loss: 0.0072, Train Indices: [   1    2    4 ... 2794 2795 2796]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Get the data for the test fold\n",
        "    y_test = test_data['bot']\n",
        "    # Vectorize the test data\n",
        "    X_test_vectorized = vectorizer.transform(test_data.apply(lambda x: ' '.join(map(str, x)), axis=1))\n",
        "    # Reshape the output labels to a 2D array\n",
        "    y_test_reshaped = np.array(y_test).reshape(-1, 1)\n",
        "    y_test_encoded = mlb.fit_transform(y_test_reshaped)\n",
        "\n",
        "    # Convert the test data to tensors\n",
        "    X_test_tensor = torch.tensor(X_test_vectorized.toarray(), dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.float32)\n",
        "\n",
        "    model = LSTMModel(input_size, hidden_size, output_size)\n",
        "    model.load_state_dict(torch.load(LSTM5folds))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(X_test_tensor.unsqueeze(1))\n",
        "        test_predictions = torch.round(torch.sigmoid(test_outputs)).numpy()\n",
        "        test_accuracy = accuracy_score(y_test_encoded, test_predictions)\n",
        "        test_f1_score = f1_score(y_test_encoded, test_predictions, average='weighted')\n",
        "\n",
        "    print(f\"Fold 5: Test Accuracy: {test_accuracy:.4f}, F1 Score: {test_f1_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxPvZFgmeiwF",
        "outputId": "4709dd8a-3500-4c86-94c3-b34fd015fd4a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5: Test Accuracy: 0.9678, F1 Score: 0.9696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1pK-GUM81cD",
        "outputId": "0ec692f7-1762-449c-cb60-20c2ec9fec0d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2238, 34776])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor.shape"
      ],
      "metadata": {
        "id": "ZHKiKZHEBSQn",
        "outputId": "4138bd17-6e36-4506-9622-a8beaf44a7fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2238, 34776])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the five training and testing setups\n",
        "setups = [\n",
        "    {'train': [0, 1, 2, 3], 'test': [4]},\n",
        "    {'train': [1, 2, 3, 4], 'test': [0]},\n",
        "    {'train': [2, 3, 4, 0], 'test': [1]},\n",
        "    {'train': [3, 4, 0, 1], 'test': [2]},\n",
        "    {'train': [4, 0, 1, 2], 'test': [3]}\n",
        "]"
      ],
      "metadata": {
        "id": "M8JJwgkOitEk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the setups\n",
        "for setup in setups:\n",
        "    # Get the training and testing folds for the current setup\n",
        "    train_indices = np.concatenate([fold_indices[fold] for fold in setup['train']])\n",
        "    test_indices = fold_indices[setup['test'][0]]\n",
        "\n",
        "\n",
        "    # Get the data for the current fold\n",
        "    train_data = df_imputed.iloc[train_indices]\n",
        "    test_data = df_imputed.iloc[test_indices]\n",
        "    test_data.to_csv('fifthfold.csv', index=False)\n",
        "    # Get the data for the training and testing folds\n",
        "    X_train = df_imputed.iloc[train_indices]\n",
        "    y_train = train_data['bot']\n",
        "    X_test = df_imputed.iloc[test_indices]\n",
        "    y_test = test_data['bot']\n",
        "\n",
        "    # Tokenize the input columns\n",
        "    vectorizer = CountVectorizer()\n",
        "    X_train_vectorized = vectorizer.fit_transform(train_data.drop('bot',axis=1).apply(lambda x: ' '.join(map(str, x)), axis=1))\n",
        "    X_test_vectorized = vectorizer.transform(X_test.apply(lambda x: ' '.join(map(str, x)), axis=1))\n",
        "\n",
        "    # Reshape the output labels to a 2D array\n",
        "    y_train_reshaped = np.array(y_train).reshape(-1, 1)\n",
        "    y_test_reshaped = np.array(y_test).reshape(-1, 1)\n",
        "\n",
        "    # Encode the output labels\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    y_train_encoded = mlb.fit_transform(y_train_reshaped)\n",
        "    y_test_encoded = mlb.transform(y_test_reshaped)\n",
        "\n",
        "    # Convert the data to tensors\n",
        "    X_train_tensor = torch.tensor(X_train_vectorized.toarray(), dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.float32)\n",
        "    X_test_tensor = torch.tensor(X_test_vectorized.toarray(), dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.float32)\n",
        "\n",
        "    # Set hyperparameters\n",
        "    input_size = X_train_tensor.shape[1]\n",
        "    hidden_size = 64\n",
        "    output_size = y_train_tensor.shape[1]\n",
        "    num_epochs = 10\n",
        "    batch_size = 32\n",
        "    learning_rate = 0.001\n",
        "\n",
        "    # Create the LSTM model\n",
        "    model = LSTMModel(input_size, hidden_size, output_size)\n",
        "\n",
        "    # Define the loss function and optimizer\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Create a DataLoader for training\n",
        "    train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    print(f\"Number of training instances: {len(train_indices)}\")\n",
        "    print(f\"Number of test instances: {len(test_indices)}\")\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        total_samples = 0\n",
        "        correct_predictions = 0\n",
        "        test_f1_score = 0.0\n",
        "        test_accuracy = 0.0\n",
        "\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X.unsqueeze(1))\n",
        "            loss = criterion(outputs.squeeze(), batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Print the training loss for each epoch\n",
        "        print(f\"Setup: {setup}, Fold: {fold},  Epoch: {epoch + 1}, Loss: {loss.item()}\")\n",
        "\n",
        "    # Save the trained model for each fold\n",
        "    LSTM5folds = f\"final_model_fold_{fold}.pth\"\n",
        "    torch.save(model.state_dict(), LSTM5folds)\n",
        "    print(\"Model saved\")\n",
        "\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(X_test_tensor.unsqueeze(1))\n",
        "        test_predictions = torch.round(torch.sigmoid(test_outputs)).numpy()\n",
        "        test_accuracy = accuracy_score(y_test_encoded, test_predictions)\n",
        "        test_f1_score = f1_score(y_test_encoded, test_predictions, average='weighted')\n",
        "        print(f\"Setup: {setup}, Fold: {fold}, Test Accuracy: {test_accuracy:.4f}, F1 Score: {test_f1_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX5Ks94kgT51",
        "outputId": "ac1cc2ba-9ca2-4f87-c49f-2640c30f2fb3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training instances: 8950\n",
            "Number of test instances: 2238\n",
            "Setup: {'train': [0, 1, 2, 3], 'test': [4]}, Fold: 3,  Epoch: 1, Loss: 0.04586196318268776\n",
            "Setup: {'train': [0, 1, 2, 3], 'test': [4]}, Fold: 3,  Epoch: 2, Loss: 0.002304759807884693\n",
            "Setup: {'train': [0, 1, 2, 3], 'test': [4]}, Fold: 3,  Epoch: 3, Loss: 0.001643808209337294\n",
            "Setup: {'train': [0, 1, 2, 3], 'test': [4]}, Fold: 3,  Epoch: 4, Loss: 0.0008973200456239283\n",
            "Setup: {'train': [0, 1, 2, 3], 'test': [4]}, Fold: 3,  Epoch: 5, Loss: 0.0004927057307213545\n",
            "Setup: {'train': [0, 1, 2, 3], 'test': [4]}, Fold: 3,  Epoch: 6, Loss: 0.10285720974206924\n",
            "Setup: {'train': [0, 1, 2, 3], 'test': [4]}, Fold: 3,  Epoch: 7, Loss: 0.0004226563323754817\n",
            "Setup: {'train': [0, 1, 2, 3], 'test': [4]}, Fold: 3,  Epoch: 8, Loss: 0.0003712282341439277\n",
            "Setup: {'train': [0, 1, 2, 3], 'test': [4]}, Fold: 3,  Epoch: 9, Loss: 0.00045409679296426475\n",
            "Setup: {'train': [0, 1, 2, 3], 'test': [4]}, Fold: 3,  Epoch: 10, Loss: 0.000972344889305532\n",
            "Model saved\n",
            "Setup: {'train': [0, 1, 2, 3], 'test': [4]}, Fold: 3, Test Accuracy: 0.9982, F1 Score: 0.9984\n",
            "Number of training instances: 8951\n",
            "Number of test instances: 2237\n",
            "Setup: {'train': [1, 2, 3, 4], 'test': [0]}, Fold: 3,  Epoch: 1, Loss: 0.05281093344092369\n",
            "Setup: {'train': [1, 2, 3, 4], 'test': [0]}, Fold: 3,  Epoch: 2, Loss: 0.004328368231654167\n",
            "Setup: {'train': [1, 2, 3, 4], 'test': [0]}, Fold: 3,  Epoch: 3, Loss: 0.0017413077875971794\n",
            "Setup: {'train': [1, 2, 3, 4], 'test': [0]}, Fold: 3,  Epoch: 4, Loss: 0.0014813144225627184\n",
            "Setup: {'train': [1, 2, 3, 4], 'test': [0]}, Fold: 3,  Epoch: 5, Loss: 0.0019205411663278937\n",
            "Setup: {'train': [1, 2, 3, 4], 'test': [0]}, Fold: 3,  Epoch: 6, Loss: 0.0003267204447183758\n",
            "Setup: {'train': [1, 2, 3, 4], 'test': [0]}, Fold: 3,  Epoch: 7, Loss: 0.0006344245048239827\n",
            "Setup: {'train': [1, 2, 3, 4], 'test': [0]}, Fold: 3,  Epoch: 8, Loss: 0.0001554248301545158\n",
            "Setup: {'train': [1, 2, 3, 4], 'test': [0]}, Fold: 3,  Epoch: 9, Loss: 0.00028619382646866143\n",
            "Setup: {'train': [1, 2, 3, 4], 'test': [0]}, Fold: 3,  Epoch: 10, Loss: 0.00025019640452228487\n",
            "Model saved\n",
            "Setup: {'train': [1, 2, 3, 4], 'test': [0]}, Fold: 3, Test Accuracy: 0.9982, F1 Score: 0.9982\n",
            "Number of training instances: 8951\n",
            "Number of test instances: 2237\n",
            "Setup: {'train': [2, 3, 4, 0], 'test': [1]}, Fold: 3,  Epoch: 1, Loss: 0.03427617624402046\n",
            "Setup: {'train': [2, 3, 4, 0], 'test': [1]}, Fold: 3,  Epoch: 2, Loss: 0.005099843256175518\n",
            "Setup: {'train': [2, 3, 4, 0], 'test': [1]}, Fold: 3,  Epoch: 3, Loss: 0.0021655329037457705\n",
            "Setup: {'train': [2, 3, 4, 0], 'test': [1]}, Fold: 3,  Epoch: 4, Loss: 0.001030172687023878\n",
            "Setup: {'train': [2, 3, 4, 0], 'test': [1]}, Fold: 3,  Epoch: 5, Loss: 0.0009078066796064377\n",
            "Setup: {'train': [2, 3, 4, 0], 'test': [1]}, Fold: 3,  Epoch: 6, Loss: 0.0004287497722543776\n",
            "Setup: {'train': [2, 3, 4, 0], 'test': [1]}, Fold: 3,  Epoch: 7, Loss: 0.00015905694453977048\n",
            "Setup: {'train': [2, 3, 4, 0], 'test': [1]}, Fold: 3,  Epoch: 8, Loss: 0.0002539399720262736\n",
            "Setup: {'train': [2, 3, 4, 0], 'test': [1]}, Fold: 3,  Epoch: 9, Loss: 0.00014061391993891448\n",
            "Setup: {'train': [2, 3, 4, 0], 'test': [1]}, Fold: 3,  Epoch: 10, Loss: 0.0001427131937816739\n",
            "Model saved\n",
            "Setup: {'train': [2, 3, 4, 0], 'test': [1]}, Fold: 3, Test Accuracy: 0.9987, F1 Score: 0.9987\n",
            "Number of training instances: 8950\n",
            "Number of test instances: 2238\n",
            "Setup: {'train': [3, 4, 0, 1], 'test': [2]}, Fold: 3,  Epoch: 1, Loss: 0.030940139666199684\n",
            "Setup: {'train': [3, 4, 0, 1], 'test': [2]}, Fold: 3,  Epoch: 2, Loss: 0.0015606540255248547\n",
            "Setup: {'train': [3, 4, 0, 1], 'test': [2]}, Fold: 3,  Epoch: 3, Loss: 0.0023191478103399277\n",
            "Setup: {'train': [3, 4, 0, 1], 'test': [2]}, Fold: 3,  Epoch: 4, Loss: 0.00029935393831692636\n",
            "Setup: {'train': [3, 4, 0, 1], 'test': [2]}, Fold: 3,  Epoch: 5, Loss: 0.00037382010486908257\n",
            "Setup: {'train': [3, 4, 0, 1], 'test': [2]}, Fold: 3,  Epoch: 6, Loss: 0.00027671997668221593\n",
            "Setup: {'train': [3, 4, 0, 1], 'test': [2]}, Fold: 3,  Epoch: 7, Loss: 0.00031669859890826046\n",
            "Setup: {'train': [3, 4, 0, 1], 'test': [2]}, Fold: 3,  Epoch: 8, Loss: 0.0001515374897280708\n",
            "Setup: {'train': [3, 4, 0, 1], 'test': [2]}, Fold: 3,  Epoch: 9, Loss: 0.00023477902868762612\n",
            "Setup: {'train': [3, 4, 0, 1], 'test': [2]}, Fold: 3,  Epoch: 10, Loss: 0.000271887838607654\n",
            "Model saved\n",
            "Setup: {'train': [3, 4, 0, 1], 'test': [2]}, Fold: 3, Test Accuracy: 0.9987, F1 Score: 0.9989\n",
            "Number of training instances: 8950\n",
            "Number of test instances: 2238\n",
            "Setup: {'train': [4, 0, 1, 2], 'test': [3]}, Fold: 3,  Epoch: 1, Loss: 0.09906142204999924\n",
            "Setup: {'train': [4, 0, 1, 2], 'test': [3]}, Fold: 3,  Epoch: 2, Loss: 0.006186337675899267\n",
            "Setup: {'train': [4, 0, 1, 2], 'test': [3]}, Fold: 3,  Epoch: 3, Loss: 0.001362062175758183\n",
            "Setup: {'train': [4, 0, 1, 2], 'test': [3]}, Fold: 3,  Epoch: 4, Loss: 0.0019218128873035312\n",
            "Setup: {'train': [4, 0, 1, 2], 'test': [3]}, Fold: 3,  Epoch: 5, Loss: 0.0011537008685991168\n",
            "Setup: {'train': [4, 0, 1, 2], 'test': [3]}, Fold: 3,  Epoch: 6, Loss: 0.00046840522554703057\n",
            "Setup: {'train': [4, 0, 1, 2], 'test': [3]}, Fold: 3,  Epoch: 7, Loss: 0.0003782361454796046\n",
            "Setup: {'train': [4, 0, 1, 2], 'test': [3]}, Fold: 3,  Epoch: 8, Loss: 0.00015920359874144197\n",
            "Setup: {'train': [4, 0, 1, 2], 'test': [3]}, Fold: 3,  Epoch: 9, Loss: 0.001093585044145584\n",
            "Setup: {'train': [4, 0, 1, 2], 'test': [3]}, Fold: 3,  Epoch: 10, Loss: 0.00019543743110261858\n",
            "Model saved\n",
            "Setup: {'train': [4, 0, 1, 2], 'test': [3]}, Fold: 3, Test Accuracy: 0.9996, F1 Score: 0.9996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j6xYFMMa8Wzd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}