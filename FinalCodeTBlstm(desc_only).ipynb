{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ2VZKf69F1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bfbab0a-1866-46cb-ba63-eee0f83a3621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-Vd2BuaneIk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import json\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hloHCtcDEpzO"
      },
      "outputs": [],
      "source": [
        "# Set the random seed\n",
        "seed = 123\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zg1scvvcSw1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "326b7d8d-ee74-4770-f395-d1966ff8bc9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Check if a GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBL8oKyJKnU7"
      },
      "outputs": [],
      "source": [
        "# Define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size,batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        out = self.fc(h_n[-1])\n",
        "        return out\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return (torch.zeros(1, batch_size, self.hidden_size),\n",
        "                torch.zeros(1, batch_size, self.hidden_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yse9s8YGc6oO"
      },
      "outputs": [],
      "source": [
        "# Load the fold datasets\n",
        "fold1 = pd.read_csv('drive/MyDrive/Colab Notebooks/twitterbotdetection/cleanfold_1.csv')\n",
        "fold2 = pd.read_csv('drive/MyDrive/Colab Notebooks/twitterbotdetection/cleanfold_2.csv')\n",
        "fold3 = pd.read_csv('drive/MyDrive/Colab Notebooks/twitterbotdetection/cleanfold_3.csv')\n",
        "fold4 = pd.read_csv('drive/MyDrive/Colab Notebooks/twitterbotdetection/cleanfold_4.csv')\n",
        "fold5 = pd.read_csv('drive/MyDrive/Colab Notebooks/twitterbotdetection/cleanfold_5.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ElB9EhHeaKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f648dbb-d013-4785-f700-26eaf400d3a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(410, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "fold1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJF2poN1ecdJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f82eb37a-7aa5-4af9-d236-14bc29c68cc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(410, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "fold2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxsGeaCBef1E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6818a37b-78f4-489d-d3cf-bb96f900ebdf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(410, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "fold3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuRstb5qeggN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "629b3aec-9d8b-4509-b7ea-b6268f96b4dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(410, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "fold4.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hacqvrwehc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54c18e9c-891b-4036-b4ac-9874b65a3c0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(410, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "fold5.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwaywo27dc96"
      },
      "outputs": [],
      "source": [
        "# Define the setups\n",
        "setups = [\n",
        "    {'train_folds': [fold2, fold3, fold4, fold5], 'test_fold': fold1},\n",
        "    {'train_folds': [fold3, fold4, fold5, fold1], 'test_fold': fold2},\n",
        "    {'train_folds': [fold4, fold5, fold1, fold2], 'test_fold': fold3},\n",
        "    {'train_folds': [fold5, fold1, fold2, fold3], 'test_fold': fold4},\n",
        "    {'train_folds': [fold1, fold2, fold3, fold4], 'test_fold': fold5},\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcCvSgewd92g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e157cae8-e6a6-4227-ee6b-863a1049253f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary saved to: vocabulary_setup1.txt\n",
            "Setup 1: Epoch: [1/10], Loss: 0.6808\n",
            "Setup 1: Epoch: [2/10], Loss: 0.6368\n",
            "Setup 1: Epoch: [3/10], Loss: 0.5251\n",
            "Setup 1: Epoch: [4/10], Loss: 0.4079\n",
            "Setup 1: Epoch: [5/10], Loss: 0.2657\n",
            "Setup 1: Epoch: [6/10], Loss: 0.2603\n",
            "Setup 1: Epoch: [7/10], Loss: 0.1660\n",
            "Setup 1: Epoch: [8/10], Loss: 0.1549\n",
            "Setup 1: Epoch: [9/10], Loss: 0.0911\n",
            "Setup 1: Epoch: [10/10], Loss: 0.0974\n",
            "Confidence scores saved to 'confidence_original1.csv'\n",
            "For Paraphrased Fold 1: Tested on: 410 instances, Test Accuracy: 0.7927, F1 Score for Label 0: 0.8081, F1 Score for Label 1: 0.7745\n",
            "Confidence_paraphrased scores saved to 'confidence_paraphrased1.csv'\n",
            "For Paraphrased Fold 1: Tested on: 410 instances, Test Accuracy: 0.7927, F1 Score for Label 0: 0.8081, F1 Score for Label 1: 0.7745\n",
            "Model saved\n",
            "\n",
            "Vocabulary saved to: vocabulary_setup2.txt\n",
            "Setup 2: Epoch: [1/10], Loss: 0.6841\n",
            "Setup 2: Epoch: [2/10], Loss: 0.6334\n",
            "Setup 2: Epoch: [3/10], Loss: 0.5276\n",
            "Setup 2: Epoch: [4/10], Loss: 0.4449\n",
            "Setup 2: Epoch: [5/10], Loss: 0.3189\n",
            "Setup 2: Epoch: [6/10], Loss: 0.2033\n",
            "Setup 2: Epoch: [7/10], Loss: 0.1732\n",
            "Setup 2: Epoch: [8/10], Loss: 0.0892\n",
            "Setup 2: Epoch: [9/10], Loss: 0.1272\n",
            "Setup 2: Epoch: [10/10], Loss: 0.0581\n",
            "Confidence scores saved to 'confidence_original2.csv'\n",
            "For Paraphrased Fold 2: Tested on: 410 instances, Test Accuracy: 0.7829, F1 Score for Label 0: 0.8069, F1 Score for Label 1: 0.7521\n",
            "Confidence_paraphrased scores saved to 'confidence_paraphrased2.csv'\n",
            "For Paraphrased Fold 2: Tested on: 410 instances, Test Accuracy: 0.7829, F1 Score for Label 0: 0.8069, F1 Score for Label 1: 0.7521\n",
            "Model saved\n",
            "\n",
            "Vocabulary saved to: vocabulary_setup3.txt\n",
            "Setup 3: Epoch: [1/10], Loss: 0.6693\n",
            "Setup 3: Epoch: [2/10], Loss: 0.6237\n",
            "Setup 3: Epoch: [3/10], Loss: 0.5362\n",
            "Setup 3: Epoch: [4/10], Loss: 0.4178\n",
            "Setup 3: Epoch: [5/10], Loss: 0.3531\n",
            "Setup 3: Epoch: [6/10], Loss: 0.2506\n",
            "Setup 3: Epoch: [7/10], Loss: 0.2014\n",
            "Setup 3: Epoch: [8/10], Loss: 0.1513\n",
            "Setup 3: Epoch: [9/10], Loss: 0.1377\n",
            "Setup 3: Epoch: [10/10], Loss: 0.0838\n",
            "Confidence scores saved to 'confidence_original3.csv'\n",
            "For Paraphrased Fold 3: Tested on: 410 instances, Test Accuracy: 0.7829, F1 Score for Label 0: 0.7866, F1 Score for Label 1: 0.7792\n",
            "Confidence_paraphrased scores saved to 'confidence_paraphrased3.csv'\n",
            "For Paraphrased Fold 3: Tested on: 410 instances, Test Accuracy: 0.7829, F1 Score for Label 0: 0.7866, F1 Score for Label 1: 0.7792\n",
            "Model saved\n",
            "\n",
            "Vocabulary saved to: vocabulary_setup4.txt\n",
            "Setup 4: Epoch: [1/10], Loss: 0.6798\n",
            "Setup 4: Epoch: [2/10], Loss: 0.6304\n",
            "Setup 4: Epoch: [3/10], Loss: 0.5256\n",
            "Setup 4: Epoch: [4/10], Loss: 0.4153\n",
            "Setup 4: Epoch: [5/10], Loss: 0.3153\n",
            "Setup 4: Epoch: [6/10], Loss: 0.1958\n",
            "Setup 4: Epoch: [7/10], Loss: 0.1623\n",
            "Setup 4: Epoch: [8/10], Loss: 0.1265\n",
            "Setup 4: Epoch: [9/10], Loss: 0.1067\n",
            "Setup 4: Epoch: [10/10], Loss: 0.0964\n",
            "Confidence scores saved to 'confidence_original4.csv'\n",
            "For Paraphrased Fold 4: Tested on: 410 instances, Test Accuracy: 0.7585, F1 Score for Label 0: 0.7745, F1 Score for Label 1: 0.7402\n",
            "Confidence_paraphrased scores saved to 'confidence_paraphrased4.csv'\n",
            "For Paraphrased Fold 4: Tested on: 410 instances, Test Accuracy: 0.7585, F1 Score for Label 0: 0.7745, F1 Score for Label 1: 0.7402\n",
            "Model saved\n",
            "\n",
            "Vocabulary saved to: vocabulary_setup5.txt\n",
            "Setup 5: Epoch: [1/10], Loss: 0.6721\n",
            "Setup 5: Epoch: [2/10], Loss: 0.6292\n",
            "Setup 5: Epoch: [3/10], Loss: 0.5645\n",
            "Setup 5: Epoch: [4/10], Loss: 0.4294\n",
            "Setup 5: Epoch: [5/10], Loss: 0.3537\n",
            "Setup 5: Epoch: [6/10], Loss: 0.2353\n",
            "Setup 5: Epoch: [7/10], Loss: 0.1618\n",
            "Setup 5: Epoch: [8/10], Loss: 0.1477\n",
            "Setup 5: Epoch: [9/10], Loss: 0.1230\n",
            "Setup 5: Epoch: [10/10], Loss: 0.1016\n",
            "Confidence scores saved to 'confidence_original5.csv'\n",
            "For Paraphrased Fold 5: Tested on: 410 instances, Test Accuracy: 0.7951, F1 Score for Label 0: 0.8073, F1 Score for Label 1: 0.7812\n",
            "Confidence_paraphrased scores saved to 'confidence_paraphrased5.csv'\n",
            "For Paraphrased Fold 5: Tested on: 410 instances, Test Accuracy: 0.7951, F1 Score for Label 0: 0.8073, F1 Score for Label 1: 0.7812\n",
            "Model saved\n",
            "\n"
          ]
        }
      ],
      "source": [
        "setup_no=1\n",
        "\n",
        "# Create empty lists to store precision and recall values\n",
        "precision_0_list = []\n",
        "recall_0_list = []\n",
        "precision_1_list = []\n",
        "recall_1_list = []\n",
        "\n",
        "precision_0_list_para = []\n",
        "recall_0_list_para = []\n",
        "precision_1_list_para = []\n",
        "recall_1_list_para = []\n",
        "\n",
        "f1_orig_0_list = []\n",
        "f1_para_0_list = []\n",
        "\n",
        "f1_orig_1_list = []\n",
        "f1_para_1_list = []\n",
        "\n",
        "# Train and evaluate for each setup\n",
        "for i, setup in enumerate(setups):\n",
        "    len_instances=0\n",
        "    train_folds = setup['train_folds']\n",
        "    test_fold = setup['test_fold']\n",
        "\n",
        "    # Concatenate all the train folds\n",
        "    train_data = pd.concat(train_folds)\n",
        "\n",
        "    train_data_cols = train_data[['location','description','verified']]\n",
        "\n",
        "    tested_ids = []\n",
        "\n",
        "    # Perform data vectorization\n",
        "    vectorizer = CountVectorizer(stop_words='english')\n",
        "    X_train_vectorized = vectorizer.fit_transform(train_data['description'])\n",
        "    X_test_vectorized = vectorizer.transform(test_fold['description'])\n",
        "\n",
        "    # Get the vocabulary (i.e., mapping from words to indices)\n",
        "    vocabulary = vectorizer.vocabulary_\n",
        "\n",
        "    # Convert the vocabulary to a JSON string\n",
        "    vocabulary_json = json.dumps(vocabulary)\n",
        "\n",
        "    # Specify the file path to save the vocabulary\n",
        "    file_path = f\"vocabulary_setup{setup_no}.txt\"\n",
        "\n",
        "    # Save the vocabulary to the text file\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(vocabulary_json)\n",
        "\n",
        "    print(f\"Vocabulary saved to: {file_path}\")\n",
        "\n",
        "    #X_test_vectorized = vectorizer.transform(test_data['text_column'])\n",
        "    y_train = train_data['bot']\n",
        "    y_test = test_fold['bot']\n",
        "\n",
        "    # Reshape the output labels to a 1D array\n",
        "    y_reshaped = np.array(y_train).reshape(-1)\n",
        "    y_test_reshaped = np.array(y_test).reshape(-1)\n",
        "\n",
        "    # Encode the output labels using LabelEncoder\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(y_reshaped)\n",
        "    y_test_encoded = label_encoder.transform(y_test_reshaped)\n",
        "\n",
        "    # Convert the data to tensors\n",
        "    X_train_tensor = torch.tensor(X_train_vectorized.toarray(), dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_encoded, dtype=torch.float32)\n",
        "    X_test_tensor = torch.tensor(X_test_vectorized.toarray(), dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.float32)\n",
        "\n",
        "\n",
        "    # Set hyperparameters\n",
        "    input_size = X_train_tensor.shape[1]\n",
        "    hidden_size = 64\n",
        "    output_size = 1\n",
        "    num_epochs = 10\n",
        "    batch_size = 32\n",
        "    learning_rate = 0.001\n",
        "\n",
        "    # Create the LSTM model\n",
        "    model = LSTMModel(input_size, hidden_size, output_size)\n",
        "    model.to(device)\n",
        "\n",
        "    # Define the loss function and optimizer\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Create a DataLoader for training\n",
        "    train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_samples = 0\n",
        "        correct_predictions = 0\n",
        "        test_f1_score = 0.0\n",
        "        test_accuracy = 0.0\n",
        "\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            batch_X = batch_X.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "            outputs = model(batch_X.unsqueeze(1))\n",
        "            batch_size = batch_X.size(0)\n",
        "\n",
        "            # Reshape the output tensor to match the target tensor shape\n",
        "            outputs = outputs.view(batch_size)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Setup {setup_no}: Epoch: [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    len_instances = sum(len(train_fold) for train_fold in train_folds)\n",
        "\n",
        "\n",
        "    # Evaluate the model on the test fold\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(X_test_tensor.to(device).unsqueeze(1))\n",
        "        test_predictions = torch.round(torch.sigmoid(test_outputs)).cpu().numpy()\n",
        "        test_accuracy = accuracy_score(y_test_encoded, test_predictions)\n",
        "        test_f1_score_orig_label0 = f1_score(y_test_encoded==0, test_predictions==0)\n",
        "        test_f1_score_orig_label1 = f1_score(y_test_encoded==1, test_predictions==1)\n",
        "\n",
        "        # Calculate precision and recall for class 0\n",
        "        precision_0 = precision_score(y_test_encoded, test_predictions, pos_label=0)\n",
        "        recall_0 = recall_score(y_test_encoded, test_predictions, pos_label=0)\n",
        "\n",
        "        # Calculate precision and recall for class 1\n",
        "        precision_1 = precision_score(y_test_encoded, test_predictions, pos_label=1)\n",
        "        recall_1 = recall_score(y_test_encoded, test_predictions, pos_label=1)\n",
        "\n",
        "        test_probabilities = torch.sigmoid(test_outputs).cpu().numpy()\n",
        "\n",
        "        # Calculate the confidence score for label 1\n",
        "        confidence_scores_label1 = test_probabilities[:, 0]\n",
        "\n",
        "        # Ensure test_predictions and y_test_encoded have the same length\n",
        "        num_instances = len(test_fold)\n",
        "        test_predictions = test_predictions[:num_instances]\n",
        "\n",
        "        # Convert the predicted labels to strings\n",
        "        predicted_labels = test_predictions.astype(str)\n",
        "\n",
        "        # Create a DataFrame with the predicted labels\n",
        "        predictions_df = pd.DataFrame({\n",
        "            'id_str': test_fold['id_str'],  # Include the 'id_str' column\n",
        "            'Predicted Label': [', '.join(labels) for labels in predicted_labels]\n",
        "        })\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        predictions_df.to_csv(f\"predictions_setup{setup_no}.csv\", index=False)\n",
        "\n",
        "        # Create a DataFrame with id_str and confidence scores\n",
        "        confidence_df = pd.DataFrame({\n",
        "            'id_str': test_fold['id_str'],\n",
        "            'Confidence Label 1 Original': confidence_scores_label1\n",
        "        })\n",
        "\n",
        "        # Specify the output CSV file path\n",
        "        csv_file = f\"confidence_original{setup_no}.csv\"\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        confidence_df.to_csv(csv_file, index=False)\n",
        "\n",
        "        print(f\"Confidence scores saved to '{csv_file}'\")\n",
        "\n",
        "        tested_ids.extend(test_fold['id_str'])\n",
        "\n",
        "        # Append precision and recall values to their respective lists\n",
        "        precision_0_list.append(precision_0)\n",
        "        recall_0_list.append(recall_0)\n",
        "        precision_1_list.append(precision_1)\n",
        "        recall_1_list.append(recall_1)\n",
        "\n",
        "        f1_orig_0_list.append(test_f1_score_orig_label0)\n",
        "        f1_orig_1_list.append(test_f1_score_orig_label1)\n",
        "\n",
        "    print(f\"For Paraphrased Fold {setup_no}: Tested on: {len(test_fold)} instances, Test Accuracy: {test_accuracy:.4f}, F1 Score for Label 0: {test_f1_score_orig_label0:.4f}, F1 Score for Label 1: {test_f1_score_orig_label1:.4f}\")\n",
        "\n",
        "    #Forparaphrasedfifthfold\n",
        "    paraphrased_fold=pd.read_csv(f'drive/MyDrive/Colab Notebooks/twitterbotdetection/cleanfold_{setup_no}.csv')\n",
        "    paraphrased_fold_filtered = paraphrased_fold[paraphrased_fold['id_str'].isin(tested_ids)]\n",
        "    X_test_vectorized = vectorizer.transform(paraphrased_fold_filtered['description'])\n",
        "\n",
        "    y_test = paraphrased_fold_filtered['bot']\n",
        "\n",
        "    y_test_reshaped = np.array(y_test).reshape(-1)\n",
        "\n",
        "    y_test_encoded = label_encoder.transform(y_test_reshaped)\n",
        "\n",
        "    X_test_tensor = torch.tensor(X_test_vectorized.toarray(), dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.float32)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(X_test_tensor.to(device).unsqueeze(1))\n",
        "        test_predictions = torch.round(torch.sigmoid(test_outputs)).cpu().numpy()\n",
        "        test_accuracy = accuracy_score(y_test_encoded, test_predictions)\n",
        "        test_f1_score_para_label0 = f1_score(y_test_encoded==0, test_predictions==0)\n",
        "        test_f1_score_para_label1 = f1_score(y_test_encoded==1, test_predictions==1)\n",
        "\n",
        "        # Calculate precision and recall for class 0\n",
        "        precision_0_para = precision_score(y_test_encoded, test_predictions, pos_label=0)\n",
        "        recall_0_para = recall_score(y_test_encoded, test_predictions, pos_label=0)\n",
        "\n",
        "        # Calculate precision and recall for class 1\n",
        "        precision_1_para = precision_score(y_test_encoded, test_predictions, pos_label=1)\n",
        "        recall_1_para = recall_score(y_test_encoded, test_predictions, pos_label=1)\n",
        "\n",
        "        test_probabilities = torch.sigmoid(test_outputs).cpu().numpy()\n",
        "\n",
        "        # Calculate the confidence score for label 1\n",
        "        confidence_paraphrased_label1 = test_probabilities[:, 0]\n",
        "\n",
        "        # Ensure test_predictions and y_test_encoded have the same length\n",
        "        num_instances = len(paraphrased_fold_filtered)\n",
        "        test_predictions = test_predictions[:num_instances]\n",
        "\n",
        "        predicted_labels = test_predictions.astype(str)\n",
        "\n",
        "        # Create a DataFrame with the predicted labels\n",
        "        predictions_df = pd.DataFrame({\n",
        "            'id_str': paraphrased_fold_filtered['id_str'],  # Include the 'id_str' column\n",
        "            'Predicted Label Original': [', '.join(labels) for labels in predicted_labels]\n",
        "        })\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        predictions_df.to_csv(f\"f{setup_no}_predictions.csv\", index=False)\n",
        "\n",
        "        # Create a DataFrame with id_str and confidence scores\n",
        "        confidence_df = pd.DataFrame({\n",
        "            'id_str': paraphrased_fold_filtered['id_str'],\n",
        "            'Confidence Label 1 Paraphrased': confidence_paraphrased_label1\n",
        "        })\n",
        "\n",
        "        # Specify the output CSV file path\n",
        "        csv_file = f\"confidence_paraphrased{setup_no}.csv\"\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        confidence_df.to_csv(csv_file, index=False)\n",
        "\n",
        "        print(f\"Confidence_paraphrased scores saved to '{csv_file}'\")\n",
        "\n",
        "        # Append precision and recall values to their respective lists\n",
        "        precision_0_list_para.append(precision_0_para)\n",
        "        recall_0_list_para.append(recall_0_para)\n",
        "        precision_1_list_para.append(precision_1_para)\n",
        "        recall_1_list_para.append(recall_1_para)\n",
        "\n",
        "        f1_para_0_list.append(test_f1_score_para_label0)\n",
        "        f1_para_1_list.append(test_f1_score_para_label1)\n",
        "\n",
        "    print(f\"For Paraphrased Fold {setup_no}: Tested on: {len(paraphrased_fold_filtered)} instances, Test Accuracy: {test_accuracy:.4f}, F1 Score for Label 0: {test_f1_score_para_label0:.4f}, F1 Score for Label 1: {test_f1_score_para_label1:.4f}\")\n",
        "\n",
        "    # Save the model after each setup\n",
        "    torch.save(model.state_dict(), f\"model_setup{setup_no}.pt\")\n",
        "    print('Model saved')\n",
        "    setup_no=setup_no+1\n",
        "\n",
        "    print()  # Add an empty line between setups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0-AREVmNbid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af6c177e-66e5-4d1b-f805-204531ee2a97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of matching instances: 410\n"
          ]
        }
      ],
      "source": [
        "# Get the 'id_str' column values from each DataFrame\n",
        "id_str1 = test_fold['id_str']\n",
        "id_str2 = paraphrased_fold['id_str']\n",
        "\n",
        "# Compare the 'id_str' values and find the matching instances\n",
        "matching_instances = id_str1.isin(id_str2)\n",
        "\n",
        "# Count the number of matching instances\n",
        "num_matching_instances = matching_instances.sum()\n",
        "\n",
        "# Display the result\n",
        "print(f\"Number of matching instances: {num_matching_instances}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYdh_JUM7xHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b10e8747-1dba-4122-b59e-fd32b138b3f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7991071428571429, 0.7591836734693878, 0.8, 0.7112970711297071, 0.7822222222222223]\n",
            "[0.817351598173516, 0.8611111111111112, 0.7735849056603774, 0.85, 0.8341232227488151]\n",
            "[0.7849462365591398, 0.8181818181818182, 0.7658536585365854, 0.8245614035087719, 0.8108108108108109]\n",
            "[0.7643979057591623, 0.6958762886597938, 0.7929292929292929, 0.6714285714285714, 0.7537688442211056]\n",
            "\n",
            "[0.7991071428571429, 0.7591836734693878, 0.8, 0.7112970711297071, 0.7822222222222223]\n",
            "[0.817351598173516, 0.8611111111111112, 0.7735849056603774, 0.85, 0.8341232227488151]\n",
            "[0.7849462365591398, 0.8181818181818182, 0.7658536585365854, 0.8245614035087719, 0.8108108108108109]\n",
            "[0.7643979057591623, 0.6958762886597938, 0.7929292929292929, 0.6714285714285714, 0.7537688442211056]\n",
            "\n",
            "[0.8081264108352145, 0.806941431670282, 0.7865707434052759, 0.7744874715261959, 0.8073394495412844]\n",
            "[0.7745358090185676, 0.7520891364902508, 0.7791563275434242, 0.7401574803149606, 0.78125]\n",
            "\n",
            "[0.8081264108352145, 0.806941431670282, 0.7865707434052759, 0.7744874715261959, 0.8073394495412844]\n",
            "[0.7745358090185676, 0.7520891364902508, 0.7791563275434242, 0.7401574803149606, 0.78125]\n"
          ]
        }
      ],
      "source": [
        "#Check the performance metrics\n",
        "print(precision_0_list)\n",
        "print(recall_0_list)\n",
        "print(precision_1_list)\n",
        "print(recall_1_list)\n",
        "print()\n",
        "print(precision_0_list_para)\n",
        "print(recall_0_list_para)\n",
        "print(precision_1_list_para)\n",
        "print(recall_1_list_para)\n",
        "print()\n",
        "print(f1_orig_0_list)\n",
        "print(f1_orig_1_list)\n",
        "print()\n",
        "print(f1_para_0_list)\n",
        "print(f1_para_1_list)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}