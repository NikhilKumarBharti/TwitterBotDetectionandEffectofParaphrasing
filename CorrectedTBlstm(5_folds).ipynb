{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ2VZKf69F1G",
        "outputId": "5ec4767d-f852-46f4-bff1-8849dde4f676"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X-Vd2BuaneIk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bRUQl1ZYar4",
        "outputId": "523b5395-eb5c-4fd1-f895-9a8b7a169c45"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg1scvvcSw1X",
        "outputId": "ddba421c-9a00-4f81-eca0-4a80b7555de2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size,batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        out = self.fc(h_n[-1])\n",
        "        return out\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return (torch.zeros(1, batch_size, self.hidden_size),\n",
        "                torch.zeros(1, batch_size, self.hidden_size))"
      ],
      "metadata": {
        "id": "HBL8oKyJKnU7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fold datasets\n",
        "fold1 = pd.read_csv('drive/MyDrive/Colab Notebooks/twitterbotdetection/fold_1.csv')\n",
        "fold2 = pd.read_csv('drive/MyDrive/Colab Notebooks/twitterbotdetection/fold_2.csv')\n",
        "fold3 = pd.read_csv('drive/MyDrive/Colab Notebooks/twitterbotdetection/fold_3.csv')\n",
        "fold4 = pd.read_csv('drive/MyDrive/Colab Notebooks/twitterbotdetection/fold_4.csv')\n",
        "fold5 = pd.read_csv('drive/MyDrive/Colab Notebooks/twitterbotdetection/fold_5.csv')"
      ],
      "metadata": {
        "id": "yse9s8YGc6oO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the last row\n",
        "fold1 = fold1.drop(fold1.index[-1])\n",
        "fold2 = fold2.drop(fold2.index[-1])"
      ],
      "metadata": {
        "id": "b55HxmzKetTY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ElB9EhHeaKl",
        "outputId": "024a2948-4ff3-4e14-88cf-2bfb217d1d5c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(559, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fold2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJF2poN1ecdJ",
        "outputId": "8fd903d4-a491-400c-8546-01ecbee825f1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(559, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fold3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxsGeaCBef1E",
        "outputId": "b78a6602-3b55-499d-d9d0-a86033c85c9b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(559, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fold4.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuRstb5qeggN",
        "outputId": "eb1893c6-0572-4976-e30f-845e845ec2e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(559, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fold5.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hacqvrwehc8",
        "outputId": "c51146d8-24d3-4cc4-8caa-ffbcb34924ea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(559, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the setups\n",
        "setups = [\n",
        "    {'train_folds': [fold1, fold2, fold3, fold4], 'test_fold': fold5},\n",
        "    {'train_folds': [fold2, fold3, fold4, fold5], 'test_fold': fold1},\n",
        "    {'train_folds': [fold3, fold4, fold5, fold1], 'test_fold': fold2},\n",
        "    {'train_folds': [fold4, fold5, fold1, fold2], 'test_fold': fold3},\n",
        "    {'train_folds': [fold5, fold1, fold2, fold3], 'test_fold': fold4}\n",
        "]"
      ],
      "metadata": {
        "id": "gwaywo27dc96"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "setup_no=1\n",
        "\n",
        "# Train and evaluate for each setup\n",
        "for i, setup in enumerate(setups):\n",
        "    len_instances=0\n",
        "    train_folds = setup['train_folds']\n",
        "    test_fold = setup['test_fold']\n",
        "\n",
        "    # Train on each fold one by one\n",
        "    #model = None  # Replace with your model initialization\n",
        "\n",
        "    for fold_num, train_fold in enumerate(train_folds):\n",
        "        # Perform data vectorization\n",
        "        vectorizer = CountVectorizer()\n",
        "        X_train_vectorized = vectorizer.fit_transform(train_fold.drop('bot',axis=1).apply(lambda x: ' '.join(map(str,x)), axis=1))\n",
        "        X_test_vectorized = vectorizer.transform(test_fold.drop('bot',axis=1).apply(lambda x: ' '.join(map(str,x)), axis=1))\n",
        "\n",
        "        #X_test_vectorized = vectorizer.transform(test_data['text_column'])\n",
        "        y_train = train_fold['bot']\n",
        "        y_test = test_fold['bot']\n",
        "\n",
        "        # Reshape the output labels to a 2D array\n",
        "        y_reshaped = np.array(y_train).reshape(-1, 1)\n",
        "        y_test_reshaped = np.array(y_test).reshape(-1, 1)\n",
        "        # Encode the output labels\n",
        "        mlb = MultiLabelBinarizer()\n",
        "        y_encoded = mlb.fit_transform(y_reshaped)\n",
        "        y_test_encoded = mlb.transform(y_test_reshaped)\n",
        "\n",
        "        # Convert the data to tensors\n",
        "        X_train_tensor = torch.tensor(X_train_vectorized.toarray(), dtype=torch.float32)\n",
        "        y_train_tensor = torch.tensor(y_encoded, dtype=torch.float32)\n",
        "        X_test_tensor = torch.tensor(X_test_vectorized.toarray(), dtype=torch.float32)\n",
        "        y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.float32)\n",
        "\n",
        "        # Set hyperparameters\n",
        "        input_size = X_train_tensor.shape[1]\n",
        "        hidden_size = 64\n",
        "        output_size = y_train_tensor.shape[1]\n",
        "        num_epochs = 10\n",
        "        batch_size = 32\n",
        "        learning_rate = 0.001\n",
        "\n",
        "        # Create the LSTM model\n",
        "        model = LSTMModel(input_size, hidden_size, output_size)\n",
        "        model.to(device)\n",
        "\n",
        "        # Define the loss function and optimizer\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "        # Create a DataLoader for training\n",
        "        train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
        "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            total_samples = 0\n",
        "            correct_predictions = 0\n",
        "            test_f1_score = 0.0\n",
        "            test_accuracy = 0.0\n",
        "\n",
        "            for batch_X, batch_y in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                batch_X = batch_X.to(device)\n",
        "                batch_y = batch_y.to(device)\n",
        "                outputs = model(batch_X.unsqueeze(1))\n",
        "                loss = criterion(outputs.squeeze(), batch_y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            print(f\"Setup {setup_no}: Epoch: [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "        len_instances = sum(len(train_fold) for train_fold in train_folds)\n",
        "\n",
        "\n",
        "\n",
        "        # Evaluate the model on the test fold\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(X_test_tensor.to(device).unsqueeze(1))\n",
        "        test_predictions = torch.round(torch.sigmoid(test_outputs)).cpu().numpy()\n",
        "        test_accuracy = accuracy_score(y_test_encoded, test_predictions)\n",
        "        test_f1_score = f1_score(y_test_encoded, test_predictions, average='weighted')\n",
        "\n",
        "    print(f\"Setup {i+1}: Trained on: {len_instances} instances, Tested on: {len(test_fold)} instances, Test Accuracy: {test_accuracy:.4f}, F1 Score: {test_f1_score:.4f}\")\n",
        "\n",
        "    # Save the model after each setup\n",
        "    torch.save(model.state_dict(), f\"model_setup{setup_no}.pt\")\n",
        "    print('Model saved')\n",
        "    setup_no=setup_no+1\n",
        "        # Replace the following lines with your model evaluation code\n",
        "        # accuracy = model.evaluate(test_fold)\n",
        "\n",
        "        #print(f\"Setup {i+1}: Trained on {len(train_fold)} instances, Tested on {len(test_fold)} instances\")\n",
        "        # Print or save the evaluation results as per your requirements\n",
        "\n",
        "    print()  # Add an empty line between setups"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcCvSgewd92g",
        "outputId": "e4f93b0f-9a0e-4f23-84fd-7942a5055c2e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup 1: Epoch: [1/10], Loss: 0.6810\n",
            "Setup 1: Epoch: [2/10], Loss: 0.6308\n",
            "Setup 1: Epoch: [3/10], Loss: 0.5417\n",
            "Setup 1: Epoch: [4/10], Loss: 0.4356\n",
            "Setup 1: Epoch: [5/10], Loss: 0.3292\n",
            "Setup 1: Epoch: [6/10], Loss: 0.2096\n",
            "Setup 1: Epoch: [7/10], Loss: 0.1361\n",
            "Setup 1: Epoch: [8/10], Loss: 0.1035\n",
            "Setup 1: Epoch: [9/10], Loss: 0.0836\n",
            "Setup 1: Epoch: [10/10], Loss: 0.0503\n",
            "Setup 1: Epoch: [1/10], Loss: 0.6871\n",
            "Setup 1: Epoch: [2/10], Loss: 0.5919\n",
            "Setup 1: Epoch: [3/10], Loss: 0.5052\n",
            "Setup 1: Epoch: [4/10], Loss: 0.3963\n",
            "Setup 1: Epoch: [5/10], Loss: 0.2614\n",
            "Setup 1: Epoch: [6/10], Loss: 0.2145\n",
            "Setup 1: Epoch: [7/10], Loss: 0.1269\n",
            "Setup 1: Epoch: [8/10], Loss: 0.0950\n",
            "Setup 1: Epoch: [9/10], Loss: 0.0713\n",
            "Setup 1: Epoch: [10/10], Loss: 0.0570\n",
            "Setup 1: Epoch: [1/10], Loss: 0.6597\n",
            "Setup 1: Epoch: [2/10], Loss: 0.5868\n",
            "Setup 1: Epoch: [3/10], Loss: 0.4935\n",
            "Setup 1: Epoch: [4/10], Loss: 0.4275\n",
            "Setup 1: Epoch: [5/10], Loss: 0.2707\n",
            "Setup 1: Epoch: [6/10], Loss: 0.1822\n",
            "Setup 1: Epoch: [7/10], Loss: 0.1079\n",
            "Setup 1: Epoch: [8/10], Loss: 0.0833\n",
            "Setup 1: Epoch: [9/10], Loss: 0.0806\n",
            "Setup 1: Epoch: [10/10], Loss: 0.0564\n",
            "Setup 1: Epoch: [1/10], Loss: 0.6730\n",
            "Setup 1: Epoch: [2/10], Loss: 0.6140\n",
            "Setup 1: Epoch: [3/10], Loss: 0.5541\n",
            "Setup 1: Epoch: [4/10], Loss: 0.4616\n",
            "Setup 1: Epoch: [5/10], Loss: 0.3200\n",
            "Setup 1: Epoch: [6/10], Loss: 0.1832\n",
            "Setup 1: Epoch: [7/10], Loss: 0.1127\n",
            "Setup 1: Epoch: [8/10], Loss: 0.1158\n",
            "Setup 1: Epoch: [9/10], Loss: 0.0768\n",
            "Setup 1: Epoch: [10/10], Loss: 0.0427\n",
            "Setup 1: Trained on: 2236 instances, Tested on: 559 instances, Test Accuracy: 0.8515, F1 Score: 0.8703\n",
            "Model saved\n",
            "\n",
            "Setup 2: Epoch: [1/10], Loss: 0.6703\n",
            "Setup 2: Epoch: [2/10], Loss: 0.5897\n",
            "Setup 2: Epoch: [3/10], Loss: 0.5162\n",
            "Setup 2: Epoch: [4/10], Loss: 0.3920\n",
            "Setup 2: Epoch: [5/10], Loss: 0.3240\n",
            "Setup 2: Epoch: [6/10], Loss: 0.2141\n",
            "Setup 2: Epoch: [7/10], Loss: 0.1302\n",
            "Setup 2: Epoch: [8/10], Loss: 0.0954\n",
            "Setup 2: Epoch: [9/10], Loss: 0.0651\n",
            "Setup 2: Epoch: [10/10], Loss: 0.0450\n",
            "Setup 2: Epoch: [1/10], Loss: 0.6663\n",
            "Setup 2: Epoch: [2/10], Loss: 0.6288\n",
            "Setup 2: Epoch: [3/10], Loss: 0.4795\n",
            "Setup 2: Epoch: [4/10], Loss: 0.4042\n",
            "Setup 2: Epoch: [5/10], Loss: 0.2831\n",
            "Setup 2: Epoch: [6/10], Loss: 0.2308\n",
            "Setup 2: Epoch: [7/10], Loss: 0.1536\n",
            "Setup 2: Epoch: [8/10], Loss: 0.0904\n",
            "Setup 2: Epoch: [9/10], Loss: 0.0587\n",
            "Setup 2: Epoch: [10/10], Loss: 0.0723\n",
            "Setup 2: Epoch: [1/10], Loss: 0.6683\n",
            "Setup 2: Epoch: [2/10], Loss: 0.5869\n",
            "Setup 2: Epoch: [3/10], Loss: 0.5016\n",
            "Setup 2: Epoch: [4/10], Loss: 0.4257\n",
            "Setup 2: Epoch: [5/10], Loss: 0.3399\n",
            "Setup 2: Epoch: [6/10], Loss: 0.1949\n",
            "Setup 2: Epoch: [7/10], Loss: 0.1264\n",
            "Setup 2: Epoch: [8/10], Loss: 0.0570\n",
            "Setup 2: Epoch: [9/10], Loss: 0.0781\n",
            "Setup 2: Epoch: [10/10], Loss: 0.0494\n",
            "Setup 2: Epoch: [1/10], Loss: 0.6668\n",
            "Setup 2: Epoch: [2/10], Loss: 0.6011\n",
            "Setup 2: Epoch: [3/10], Loss: 0.4651\n",
            "Setup 2: Epoch: [4/10], Loss: 0.3587\n",
            "Setup 2: Epoch: [5/10], Loss: 0.2214\n",
            "Setup 2: Epoch: [6/10], Loss: 0.2035\n",
            "Setup 2: Epoch: [7/10], Loss: 0.1237\n",
            "Setup 2: Epoch: [8/10], Loss: 0.1014\n",
            "Setup 2: Epoch: [9/10], Loss: 0.0456\n",
            "Setup 2: Epoch: [10/10], Loss: 0.0533\n",
            "Setup 2: Trained on: 2236 instances, Tested on: 559 instances, Test Accuracy: 0.8247, F1 Score: 0.8433\n",
            "Model saved\n",
            "\n",
            "Setup 3: Epoch: [1/10], Loss: 0.6467\n",
            "Setup 3: Epoch: [2/10], Loss: 0.6368\n",
            "Setup 3: Epoch: [3/10], Loss: 0.4839\n",
            "Setup 3: Epoch: [4/10], Loss: 0.3844\n",
            "Setup 3: Epoch: [5/10], Loss: 0.2862\n",
            "Setup 3: Epoch: [6/10], Loss: 0.1771\n",
            "Setup 3: Epoch: [7/10], Loss: 0.1248\n",
            "Setup 3: Epoch: [8/10], Loss: 0.0980\n",
            "Setup 3: Epoch: [9/10], Loss: 0.0636\n",
            "Setup 3: Epoch: [10/10], Loss: 0.0665\n",
            "Setup 3: Epoch: [1/10], Loss: 0.6851\n",
            "Setup 3: Epoch: [2/10], Loss: 0.6037\n",
            "Setup 3: Epoch: [3/10], Loss: 0.5078\n",
            "Setup 3: Epoch: [4/10], Loss: 0.4043\n",
            "Setup 3: Epoch: [5/10], Loss: 0.3030\n",
            "Setup 3: Epoch: [6/10], Loss: 0.2141\n",
            "Setup 3: Epoch: [7/10], Loss: 0.1529\n",
            "Setup 3: Epoch: [8/10], Loss: 0.0998\n",
            "Setup 3: Epoch: [9/10], Loss: 0.0540\n",
            "Setup 3: Epoch: [10/10], Loss: 0.0558\n",
            "Setup 3: Epoch: [1/10], Loss: 0.6584\n",
            "Setup 3: Epoch: [2/10], Loss: 0.6207\n",
            "Setup 3: Epoch: [3/10], Loss: 0.5169\n",
            "Setup 3: Epoch: [4/10], Loss: 0.3865\n",
            "Setup 3: Epoch: [5/10], Loss: 0.2579\n",
            "Setup 3: Epoch: [6/10], Loss: 0.1985\n",
            "Setup 3: Epoch: [7/10], Loss: 0.1239\n",
            "Setup 3: Epoch: [8/10], Loss: 0.1356\n",
            "Setup 3: Epoch: [9/10], Loss: 0.0703\n",
            "Setup 3: Epoch: [10/10], Loss: 0.0407\n",
            "Setup 3: Epoch: [1/10], Loss: 0.6507\n",
            "Setup 3: Epoch: [2/10], Loss: 0.5931\n",
            "Setup 3: Epoch: [3/10], Loss: 0.5099\n",
            "Setup 3: Epoch: [4/10], Loss: 0.3777\n",
            "Setup 3: Epoch: [5/10], Loss: 0.3260\n",
            "Setup 3: Epoch: [6/10], Loss: 0.1849\n",
            "Setup 3: Epoch: [7/10], Loss: 0.1116\n",
            "Setup 3: Epoch: [8/10], Loss: 0.1102\n",
            "Setup 3: Epoch: [9/10], Loss: 0.0551\n",
            "Setup 3: Epoch: [10/10], Loss: 0.0436\n",
            "Setup 3: Trained on: 2236 instances, Tested on: 559 instances, Test Accuracy: 0.8104, F1 Score: 0.8280\n",
            "Model saved\n",
            "\n",
            "Setup 4: Epoch: [1/10], Loss: 0.6768\n",
            "Setup 4: Epoch: [2/10], Loss: 0.6134\n",
            "Setup 4: Epoch: [3/10], Loss: 0.5042\n",
            "Setup 4: Epoch: [4/10], Loss: 0.3891\n",
            "Setup 4: Epoch: [5/10], Loss: 0.2503\n",
            "Setup 4: Epoch: [6/10], Loss: 0.1785\n",
            "Setup 4: Epoch: [7/10], Loss: 0.1419\n",
            "Setup 4: Epoch: [8/10], Loss: 0.0899\n",
            "Setup 4: Epoch: [9/10], Loss: 0.1078\n",
            "Setup 4: Epoch: [10/10], Loss: 0.0482\n",
            "Setup 4: Epoch: [1/10], Loss: 0.6766\n",
            "Setup 4: Epoch: [2/10], Loss: 0.6482\n",
            "Setup 4: Epoch: [3/10], Loss: 0.5039\n",
            "Setup 4: Epoch: [4/10], Loss: 0.4036\n",
            "Setup 4: Epoch: [5/10], Loss: 0.3075\n",
            "Setup 4: Epoch: [6/10], Loss: 0.1962\n",
            "Setup 4: Epoch: [7/10], Loss: 0.1377\n",
            "Setup 4: Epoch: [8/10], Loss: 0.0879\n",
            "Setup 4: Epoch: [9/10], Loss: 0.0573\n",
            "Setup 4: Epoch: [10/10], Loss: 0.0679\n",
            "Setup 4: Epoch: [1/10], Loss: 0.6654\n",
            "Setup 4: Epoch: [2/10], Loss: 0.5771\n",
            "Setup 4: Epoch: [3/10], Loss: 0.5187\n",
            "Setup 4: Epoch: [4/10], Loss: 0.3999\n",
            "Setup 4: Epoch: [5/10], Loss: 0.2387\n",
            "Setup 4: Epoch: [6/10], Loss: 0.1633\n",
            "Setup 4: Epoch: [7/10], Loss: 0.1127\n",
            "Setup 4: Epoch: [8/10], Loss: 0.0757\n",
            "Setup 4: Epoch: [9/10], Loss: 0.0696\n",
            "Setup 4: Epoch: [10/10], Loss: 0.0342\n",
            "Setup 4: Epoch: [1/10], Loss: 0.6712\n",
            "Setup 4: Epoch: [2/10], Loss: 0.6101\n",
            "Setup 4: Epoch: [3/10], Loss: 0.5155\n",
            "Setup 4: Epoch: [4/10], Loss: 0.3731\n",
            "Setup 4: Epoch: [5/10], Loss: 0.2599\n",
            "Setup 4: Epoch: [6/10], Loss: 0.1753\n",
            "Setup 4: Epoch: [7/10], Loss: 0.1328\n",
            "Setup 4: Epoch: [8/10], Loss: 0.0748\n",
            "Setup 4: Epoch: [9/10], Loss: 0.0665\n",
            "Setup 4: Epoch: [10/10], Loss: 0.0439\n",
            "Setup 4: Trained on: 2236 instances, Tested on: 559 instances, Test Accuracy: 0.8301, F1 Score: 0.8400\n",
            "Model saved\n",
            "\n",
            "Setup 5: Epoch: [1/10], Loss: 0.6488\n",
            "Setup 5: Epoch: [2/10], Loss: 0.5892\n",
            "Setup 5: Epoch: [3/10], Loss: 0.4820\n",
            "Setup 5: Epoch: [4/10], Loss: 0.3719\n",
            "Setup 5: Epoch: [5/10], Loss: 0.2676\n",
            "Setup 5: Epoch: [6/10], Loss: 0.1768\n",
            "Setup 5: Epoch: [7/10], Loss: 0.1636\n",
            "Setup 5: Epoch: [8/10], Loss: 0.1053\n",
            "Setup 5: Epoch: [9/10], Loss: 0.0473\n",
            "Setup 5: Epoch: [10/10], Loss: 0.0594\n",
            "Setup 5: Epoch: [1/10], Loss: 0.6604\n",
            "Setup 5: Epoch: [2/10], Loss: 0.5654\n",
            "Setup 5: Epoch: [3/10], Loss: 0.5025\n",
            "Setup 5: Epoch: [4/10], Loss: 0.3568\n",
            "Setup 5: Epoch: [5/10], Loss: 0.2316\n",
            "Setup 5: Epoch: [6/10], Loss: 0.1861\n",
            "Setup 5: Epoch: [7/10], Loss: 0.0950\n",
            "Setup 5: Epoch: [8/10], Loss: 0.0708\n",
            "Setup 5: Epoch: [9/10], Loss: 0.0716\n",
            "Setup 5: Epoch: [10/10], Loss: 0.0395\n",
            "Setup 5: Epoch: [1/10], Loss: 0.6814\n",
            "Setup 5: Epoch: [2/10], Loss: 0.5955\n",
            "Setup 5: Epoch: [3/10], Loss: 0.5071\n",
            "Setup 5: Epoch: [4/10], Loss: 0.3840\n",
            "Setup 5: Epoch: [5/10], Loss: 0.2467\n",
            "Setup 5: Epoch: [6/10], Loss: 0.1957\n",
            "Setup 5: Epoch: [7/10], Loss: 0.1445\n",
            "Setup 5: Epoch: [8/10], Loss: 0.0841\n",
            "Setup 5: Epoch: [9/10], Loss: 0.0642\n",
            "Setup 5: Epoch: [10/10], Loss: 0.0469\n",
            "Setup 5: Epoch: [1/10], Loss: 0.6664\n",
            "Setup 5: Epoch: [2/10], Loss: 0.6151\n",
            "Setup 5: Epoch: [3/10], Loss: 0.5767\n",
            "Setup 5: Epoch: [4/10], Loss: 0.4448\n",
            "Setup 5: Epoch: [5/10], Loss: 0.2936\n",
            "Setup 5: Epoch: [6/10], Loss: 0.1916\n",
            "Setup 5: Epoch: [7/10], Loss: 0.1356\n",
            "Setup 5: Epoch: [8/10], Loss: 0.1057\n",
            "Setup 5: Epoch: [9/10], Loss: 0.0581\n",
            "Setup 5: Epoch: [10/10], Loss: 0.0621\n",
            "Setup 5: Trained on: 2236 instances, Tested on: 559 instances, Test Accuracy: 0.8140, F1 Score: 0.8363\n",
            "Model saved\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-pUfBU__9wk",
        "outputId": "24a897c8-cd02-49cb-a392-a5321dd6cb42"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([559, 11318])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnO0VWebAA5N",
        "outputId": "0d976e4a-b0d0-4152-f248-21e9a40a0d93"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([559, 11318])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}